\documentclass[10pt,fleqn]{article}
\input{/home/clair/Documents/definitions}
% add document-specific packages here

\titleformat{\section}
    {\normalfont\bfseries}
    {\llap{\parbox{1cm}{\thesection}}}{0em}{}
    
\begin{document}
\renewenvironment{knitrout}{\vspace{1em}}{\vspace{1em}}
<<setup, include=FALSE>>=
opts_chunk$set(size = 'footnotesize',   # smaller font size for chunks
               out.width = '0.25\\textwidth',   # default figure size = quarter of text width
               fig.show = 'hold',   # display all figures at end of chunk
               fig.align='center')
options(width = 80, digits = 4)
set.seed(24747)
library(xtable)

org.par <- par()
par(mar = c(2,2,0,0))
library(circular); library(FNN)
@

<<functions, echo = F>>=
# angular functions
k.nearest.angles <- function(pts, k) {
    
    nn <- knn.index(p, k = k)
    angles <- matrix(NA, nrow = nrow(pts), ncol = nrow(pts))
    for (i in 1:nrow(pts)) {
        for (j in 1:k) {
            nn[i,j]
            diff.x <- pts[nn[i,j], 1] - pts[i, 1]
            diff.y <- pts[nn[i,j], 2] - pts[i, 2]
            angles[i, nn[i,j]] <- atan2(diff.y, diff.x)
        }
    }
    cbind(pts, angles)
}

show.directions <- function(angles, l = 0.01) {
    
    plot(angles[,1:2], col = "lightgrey", pch = 20, cex = 0.5, asp = T)
    
    for (i in 1:nrow(angles)) {
        for (j in 3:nrow(angles)) {
            if (!is.na(angles[i,j])) {
                x.end <- angles[i,1] + (cos(angles[i,j]) * l)
                y.end <- angles[i,2] + (sin(angles[i,j]) * l)
                segments(angles[i,1], angles[i,2], x.end, y.end)
            }
        }
    }
}

#-------------------------------------------------------------------------

get.moments <- function(data) {
    
    t2 <- trigonometric.moment(data, p = 2, center = T)
    t3 <- trigonometric.moment(data, p = 3, center = T)
    t4 <- trigonometric.moment(data, p = 4, center = T)
    
    list(mu = as.numeric(mean(data)),
         r = rho.circular(data),
         b2 = t2$sin,
         b3 = t3$sin,
         b4 = t4$sin,
         a2 = t2$cos,
         a3 = t3$cos,
         a4 = t4$cos)
}

uniformity.plot <- function(data, extend = F, title = T) {
    if (circularp(data)$units == "degrees") {
        data <- conversion.circular(data, units = "radians")
    }
    data <- data %% (2 * pi)
    n <- length(data)
    
    x <- c(1:n)/(n+1)
    y <- sort(data) / (2 * pi)
    
    if(title) {
        m <- "Uniformity plot"
        s <- 1
    if (extend) {
        floor(n/5)
        x.end <- x[1:floor(n/5)] + 1
        y.end <- y[1:floor(n/5)] + 1
        
        x.start <- x[(n - floor(n/5)):n] - 1
        y.start <- y[(n - floor(n/5)):n] - 1
        
        x <- c(x.start, x, x.end)
        y <- c(y.start, y, y.end)
        m <- "Extended uniformity plot"
    }} else {
        m <- ""
        s <- 0
    }    
    
    par(mar = c(4,4,3,1), mai=c(1.1, 1.1, s, 0))
    plot(x, y, pch = 20, asp = T, xlab = "", ylab = "")
    title(m, cex.main = set.cex.main,
          xlab = "Uniform quantiles", ylab = "Sample quantiles", cex.lab = set.cex.lab)
    abline(a = 0, b = 1, col = "lightseagreen")
}

uniformity.tests <- function(data) {
    list(kuiper.stat = eval(kuiper.test(data, alpha = 0.05))$statistic, 
      kuiper = eval(kuiper.test(data, alpha = 0.05))$statistic > 1.747,
      watson.statistic = eval(watson.test(data, alpha = 0.05))$statistic,
      watson = eval(watson.test(data, alpha = 0.05))$statistic > 0.187,
      rao.statistic = eval(rao.spacing.test(data, alpha = 0.05))$statistic,
      rao = eval(rao.spacing.test(data, alpha = 0.05))$statistic > 140.57,
      rayleigh.s = rayleigh.test(data)$statistic,
      rayleigh.p = round(rayleigh.test(data)$p.val, 3),
      rayleigh = rayleigh.test(data)$p.val < 0.05)
}

r.symm.test.stat <- function(data) {
    n <- length(data)
    bar <- get.moments(data)
    
    var <- ((1-bar$a4)/2-(2*bar$a2)+(2*bar$a2/bar$r) * (bar$a3 + (bar$a2*(1-bar$a2)/bar$r)))/n
    ts <- abs(bar$b2/sqrt(var))
    pval <- 2*pnorm(ts, mean = 0, sd = 1, lower = F)
    list(test.statistic = ts, p.val = pval)
}

#-------------------------------------------------------------------------

bc.point.estimates <- function(data, sig = 0.05, symmetric = F) {
    
    n <- length(data)
    bar <- get.moments(data)
    bar$mu <- bar$mu %% (2*pi)
    r2 <- bar$r^2 ; r4 <- r2^2
    
    qval <- qnorm(1-sig/2)
    
    rho.bc <- bar$r - ((1-bar$a2)/(4*n*bar$r))
    r.SE <- sqrt((1-2*r2+bar$a2)/(2*n))    
    rho.upper <- rho.bc + qval*r.SE
    rho.lower <- rho.bc - qval*r.SE
    
    rho <- c(estimate = rho.bc, lower = rho.lower, upper = rho.upper)
    
    if (symmetric) {
        beta2 <- c(estimate = 0, lower = 0, upper = 0)
        } else {    
            beta2.bc <- bar$b2 + ((bar$b3/bar$r)+(bar$b2/r2)-(2*bar$a2*bar$b2/r4))/n
            beta2.SE <- sqrt((((1-bar$a4)/2)-(2*bar$a2)-(bar$b2^2)+(2*bar$a2/bar$r)*(bar$a3+(bar$a2*(1-bar$a2)/bar$r)))/n)
            beta2.upper <- beta2.bc + qval*beta2.SE
            beta2.lower <- beta2.bc - qval*beta2.SE
            
            beta2 <- c(estimate = beta2.bc, lower = beta2.lower, upper = beta2.upper)
        }
    
    div <- 2*n*r2 
    
    mu.bc <- bar$mu + (bar$b2/div)
    mu.SE <- sqrt((1-bar$a2)/div)
    
    mu.upper <- mu.bc + qval * mu.SE
    mu.lower <- mu.bc - qval * mu.SE
    
    mu <- c(estimate = mu.bc, lower = mu.lower, upper = mu.upper)
    
    alpha2.bc <- bar$a2 - (1-(bar$a3/bar$r)-((bar$a2*(1-bar$a2)+bar$b2*bar$b2)/r2))/n
    alpha2.SE <- sqrt((((1+bar$a4)/2)-(bar$a2*bar$a2)+(2*bar$b2/bar$r)*(bar$b3+(bar$b2*(1-bar$a2)/bar$r)))/n)
    alpha2.upper <- alpha2.bc + qval*alpha2.SE
    alpha2.lower <- alpha2.bc - qval*alpha2.SE
    
    alpha2 <- c(estimate = alpha2.bc, lower = alpha2.lower, upper = alpha2.upper)
    
    list(sig = sig, symmetric = symmetric, mu = mu, rho = rho, beta2 = beta2, alpha2 = alpha2)
}

vM.PP <- function(data, mu, kappa, title = T)  {
    edf <- ecdf(data)
    tdf <- pvonmises(data, mu, kappa, from=circular(0), tol = 1e-06)
    
    if (title) {
        t = "P-P plot of data vs von Mises"
        s = 1
    } else {
        t = ""
        s = 0
    }
    
    c.par <- par()
    par(mar = c(4,4,3,1), mai=c(1.1, 1.1, s, 0))
    plot.default(tdf, edf(data), pch=20, xlim=c(0,1), ylim=c(0,1), xlab = "", ylab = "")
    title(t, cex.main = set.cex.main, font.main = 1,
          xlab = "von Mises distribution function", ylab = "Empirical distribution function", cex.lab = set.cex.lab)
    lines(c(0,1), c(0,1), lwd=2, col = "lightseagreen")
    par(mar = c.par$mar, mai = c.par$mai)
}

vM.QQ <- function(data, mu, kappa, title = T)  {
    edf <- ecdf(data)
    tqf <- qvonmises(edf(data), mu, kappa, from=circular(0), tol = 1e-06)
    
    if (title) {
        t = "Q-Q plot of data vs von Mises"
        s = 1
    } else {
        t = ""
        s = 0
    }
    
    c.par <- par()
    par(mar = c(4,4,3,1), mai=c(1.1, 1.1, s, 0))
    
    plot.default(tqf, data, pch=20, xlim=c(0,2*pi), ylim=c(0,2*pi), xlab = "", ylab = "")
    title(t, cex.main = set.cex.main, font.main = 1,
          xlab = "von Mises quantile function", ylab = "Empirical quantile function", cex.lab = set.cex.lab)
    lines(c(0,2*pi), c(0,2*pi), lwd=2, col = "lightseagreen")
    par(mar = c.par$mar, mai = c.par$mai)
}

vM.GoF <- function(data, mu, kappa, rao.limit = 140.57) {
    tdf <- pvonmises(data, circular(mu), kappa, from=circular(0), tol = 1e-06)
    cunif <- circular(2*pi*tdf)
    
    list(watson.vM = watson.test(data, alpha = 0.05, dist = "vonmises")$statistic > 0.066,
         kuiper.unif = kuiper.test(cunif, alpha = 0.05)$statistic > 1.747,
         watson.unif = watson.test(cunif, alpha = 0.05)$statistic > 0.187,
         rao.unif = rao.spacing.test(cunif, alpha = 0.05)$statistic > rao.limit,
         rayleigh.unif = rayleigh.test(cunif)$p.val < 0.05,
         rayleigh.unif.pval = round(rayleigh.test(cunif)$p.val, 3))
}

vM.GoF.boot <- function(data, B = 9999) {
    
    n <- length(data)
    vM.mle <- mle.vonmises(data, bias=TRUE)
    mu.0 <- vM.mle$mu
    kappa.0 <- vM.mle$kappa
    
    tdf <- pvonmises(data, mu.0, kappa.0, from=circular(0), tol = 1e-06)
    cunif <- circular(2*pi*tdf)
    
    unif.test.0 <- rep(0,4)
    nxtrm <- rep(1,4)
    
    unif.test.0[1] <- kuiper.test(cunif)$statistic
    unif.test.0[2] <- watson.test(cunif)$statistic
    unif.test.0[3] <- rao.spacing.test(cunif)$statistic
    unif.test.0[4] <- rayleigh.test(cunif)$statistic
    
    for (b in 2:(B+1)) {
        bootstrap.sample <- rvonmises(n, mu.0, kappa.0)
        vM.mle <- mle.vonmises(bootstrap.sample, bias = T)
        mu.1 <- vM.mle$mu
        kappa.1 <- vM.mle$kappa
        
        tdf <- pvonmises(bootstrap.sample, mu.1, kappa.1, from=circular(0), tol = 1e-06)
        cunif <- circular(2*pi*tdf)
        
        nxtrm[1] <- nxtrm[1] + (kuiper.test(cunif)$statistic >= unif.test.0[1])
        nxtrm[2] <- nxtrm[2] + (watson.test(cunif)$statistic >= unif.test.0[2])
        nxtrm[3] <- nxtrm[3] + (rao.spacing.test(cunif)$statistic >= unif.test.0[3])
        nxtrm[4] <- nxtrm[4] + (rayleigh.test(cunif)$statistic >= unif.test.0[4])
    }
    p.val <- nxtrm/(B+1)
    names(p.val) <- c("kuiper", "watson", "rao", "rayleigh")
    p.val
}

#-------------------------------------------------------------------------

JP.NCon <- function(kappa, psi){
    if (kappa < 0.001) {ncon <- 1/(2*pi) ; return(ncon)} 
    else {
        eps <- 10*.Machine$double.eps
        if (abs(psi) <= eps) {ncon <- 1/(2*pi*I.0(kappa)) ; return(ncon)}
        
        
        else {
            intgrnd <- function(x){ (cosh(kappa*psi)+sinh(kappa*psi)*cos(x))**(1/psi) }
            
            ncon <- 1/integrate(intgrnd, lower=-pi, upper=pi)$value
            return(ncon) } }
}

JP.pdf <- function(theta, mu, kappa, psi, ncon){
    if (kappa < 0.001) {pdfval <- 1/(2*pi) ; return(pdfval)}
    else {
        eps <- 10*.Machine$double.eps
        if (abs(psi) <= eps) {
            pdfval <- ncon*exp(kappa*cos(theta-mu)) ; return(pdfval) }
        
        
        else { 
            pdfval <- (cosh(kappa*psi)+sinh(kappa*psi)*cos(theta-mu))**(1/psi)
            pdfval <- ncon*pdfval ; return(pdfval) } }
    
}

JP.df <- function(theta, mu, kappa, psi, ncon) {
    eps <- 10*.Machine$double.eps
    if (theta <= eps) {dfval <- 0 ; return(dfval)}
    
    else 
        if (theta >= 2*pi-eps) {dfval <- 1 ; return(dfval)} else
            if (kappa < 0.001) {dfval <- theta/(2*pi) ; return(dfval)}
    else {
        if (abs(psi) <= eps) {
            vMPDF <- function(x){ ncon*exp(kappa*cos(x-mu)) }
            dfval <- integrate(vMPDF, lower=0, upper=theta)$value
            return(dfval) }
        
        
        else { 
            dfval <- integrate(JP.pdf, mu=mu, kappa=kappa, psi=psi, ncon=ncon, lower=0, upper=theta)$value
            return(dfval) }
    }
}

JP.qf <- function(u, mu, kappa, psi, ncon) {
    
    eps <- 10*.Machine$double.eps
    if (u <= eps) {theta <- 0 ; return(theta)}
    
    else 
        if (u >= 1-eps) {theta <- 2*pi-eps ; return(theta)} else
            if (kappa < 0.001) {theta <- u*2*pi ; return(theta)}
    else {
        roottol <- .Machine$double.eps**(0.6)
        qzero <- function(x) {
            y <- JP.df(x, mu, kappa, psi, ncon) - u ; return(y) }
        res <- uniroot(qzero, lower=0, upper=2*pi-eps, tol=roottol)
        theta <- res$root ; return(theta) }
}

JP.sim <- function(n, mu, kappa, psi, ncon) {
    
    fmax <- JP.pdf(mu, mu, kappa, psi, ncon) ; theta <- 0
    for (j in 1:n) {
        stopgo <- 0
        while (stopgo == 0) {
            u1 <- runif(1, 0, 2*pi)
            pdfu1 <- JP.pdf(u1, mu, kappa, psi, ncon)
            u2 <- runif(1, 0, fmax)
            if (u2 <= pdfu1) { theta[j] <- u1 ; stopgo <- 1 }
        } }
    return(theta)
}

#-------------------------------------------------------------------------

mle.jonespewsey <- function(data) {
    n <- length(data)
    s <- sum(sin(data))
    c <- sum(cos(data))
    muvM <- atan2(s,c) %% (2*pi)
    kapvM <- A1inv(sqrt(s*s+c*c)/n)
    
    JPnll <- function(p){
        mu <- p[1] ; kappa <- p[2] ; psi <- p[3] ; parlim <- abs(kappa*psi)
        if (parlim > 10) {
            y <- 9999.0
            return(y)
        } else {
            ncon <- JP.NCon(kappa, psi)
            y <- -sum(log(JP.pdf(data, mu, kappa, psi, ncon)))
            return (y)
        }
    }
    
    out <- optim(par=c(muvM, kapvM, 0.001), fn=JPnll, gr = NULL, method = "L-BFGS-B", lower = c(muvM-pi, 0, -Inf), upper = c(muvM+pi, Inf, Inf), hessian = TRUE)
  
    list(maxll = -out$value,
         mu = out$par[1] %% (2*pi),
         kappa = out$par[2],
         psi = out$par[3],
         HessMat = out$hessian)
}

jp.ci.nt <- function(jp.ests, alpha = 0.05) {
    quant <- qnorm(1-alpha/2)
    infmat <- solve(jp.ests$HessMat)
    standerr <- sqrt(diag(infmat))
    
    list(alpha = alpha,
         mu = c(est = jp.ests$mu, lower = jp.ests$mu-(quant*standerr[1]), upper = jp.ests$mu+(quant*standerr[1])),
         kappa = c(est = jp.ests$kappa, lower = jp.ests$kappa-(quant*standerr[2]), upper = jp.ests$kappa+(quant*standerr[2])),
         psi = c(est = jp.ests$psi, lower = jp.ests$psi-(quant*standerr[3]), upper = jp.ests$psi+(quant*standerr[3]))    )
}

JP.PP <- function(data, mu, kappa, psi, title = T) {
    n <- length(data)
    ncon <- JP.NCon(kappa,psi) 
    edf <- ecdf(data) 
    tdf <- 0 
    for (j in 1:n) {tdf[j] <- JP.df(data[j], mu, kappa, psi, ncon)}
    
    if (title) {
        t = "P-P plot of data vs Jones-Pewsey"
        s = 1
    } else {
        t = ""
        s = 0
    }
    
    c.par <- par()
    par(mar = c(4,4,3,1), mai=c(1.1, 1.1, s, 0))
    plot.default(tdf, edf(data), pch=20, xlim=c(0,1), ylim=c(0,1), xlab = "", ylab = "")
    title(t, cex.main = set.cex.main, font.main = 1,
         xlab = "Jones-Pewsey distribution function", ylab = "Empirical distribution function", cex.lab = set.cex.lab)
    lines(c(0,1), c(0,1), lwd=2, col = "lightseagreen")
    par(mar = c.par$mar, mai = c.par$mai)
}

JP.QQ <- function(data, mu, kappa, psi, title = T) {
    n <- length(data)
    ncon <- JP.NCon(kappa, psi) 
    edf <- ecdf(data) 
    tqf <- 0 
    for (j in 1:n) {tqf[j] <- JP.qf(edf(data)[j], mu, kappa, psi, ncon)}
    
    if (title) {
        t = "Q-Q plot of data vs Jones-Pewsey"
        s = 1
    } else {
        t = ""
        s = 0
    }
    
    c.par <- par()
    par(mar = c(4,4,3,1), mai=c(1.1, 1.1, s, 0))
    plot.default(tqf, data, pch=20, xlim=c(0,2*pi), ylim=c(0,2*pi), xlab = "", ylab = "") 
    title(t, cex.main = set.cex.main, font.main = 1,
         xlab = "Jones-Pewsey quantile function", ylab = "Empirical quantile function", cex.lab = set.cex.lab)
    lines(c(0,2*pi), c(0,2*pi), lwd=2, col = "lightseagreen")
    par(mar = c.par$mar, mai = c.par$mai)
}

JP.GoF.pvals <- function(data, mu, kappa, psi) {
    n <- length(data)
    ncon <- JP.NCon(kappa, psi)
    tdf <- 0
    
    for (j in 1:n) {tdf[j] <- JP.df(data[j], mu, kappa, psi, ncon)}
    cunif <- circular(2*pi*tdf)
    
    list(kuiper.res = kuiper.test(cunif),
         watson.res = watson.test(cunif),
         rao.res = rao.spacing.test(cunif),
         rayleigh.res = rayleigh.test(cunif))
}

JP.GoF.critical <- function(data, mu, kappa, psi, sig = 0.05) {
    n <- length(data)
    ncon <- JP.NCon(kappa, psi)
    tdf <- 0
    
    for (j in 1:n) {tdf[j] <- JP.df(data[j], mu, kappa, psi, ncon)}
    cunif <- circular(2*pi*tdf)
    
    list(kuiper.res = kuiper.test(cunif, alpha = sig),
         watson.res = watson.test(cunif, alpha = sig),
         rao.res = rao.spacing.test(cunif, alpha = sig),
         rayleigh.res = rayleigh.test(cunif))
}

JP.GoF <- function(data, mu, kappa, psi, sig = 0.05, rao.limit = 140.57) {
    n <- length(data)
    ncon <- JP.NCon(kappa, psi)
    tdf <- 0
    
    for (j in 1:n) {tdf[j] <- JP.df(data[j], mu, kappa, psi, ncon)}
    cunif <- circular(2*pi*tdf)
    
    list(kuiper.unif = kuiper.test(cunif, alpha = sig)$statistic > 1.747,
         watson.unif = watson.test(cunif, alpha = sig)$statistic > 0.187,
         rao.unif = rao.spacing.test(cunif, alpha = sig)$statistic > rao.limit,
         rayleigh.unif = rayleigh.test(cunif)$p.val < sig,
         rayleigh.unif.pval = round(rayleigh.test(cunif)$p.val, 3))
}

JP.GoF.boot <- function(data, B = 9999) {
    n <- length(data)
    JPmleRes <- mle.jonespewsey(data) 
    muhat0 <- JPmleRes$mu
    kaphat0 <- JPmleRes$kappa
    psihat0 <- JPmleRes$psi
    
    ncon.0 <- JP.NCon(kaphat0, psihat0) 
    tdf <- 0 
    for (j in 1:n) {
        tdf[j] <- JP.df(data[j], muhat0, kaphat0, psihat0, ncon.0)
    }
    
    cunif <- circular(2*pi*tdf)
    nxtrm <- rep(1,4)
    
    unif.test.0 <- c(kuiper.test(cunif)$statistic, 
                     watson.test(cunif)$statistic,
                     rao.spacing.test(cunif)$statistic,
                     rayleigh.test(cunif)$statistic)
    
    pb <- txtProgressBar(min = 0, max = B, style = 3)
    for (b in 2:(B+1)) {
        bootstrap.sample <- JP.sim(n, muhat0, kaphat0, psihat0, ncon.0)
        JPmleRes <- mle.jonespewsey(bootstrap.sample) 
        muhat1 <- JPmleRes$mu
        kaphat1 <- JPmleRes$kappa
        psihat1 <- JPmleRes$psi
        ncon1 <- JPNCon(kaphat1, psihat1) 
        tdf <- 0
        for (j in 1:n) {
            tdf[j] <- JP.df(bootstrap.sample[j], muhat1, kaphat1, psihat1, ncon1)
        }
        cunif <- circular(2*pi*tdf)
        
        nxtrm[1] <- nxtrm[1] + (kuiper.test(cunif)$statistic >= unif.test.0[1])

        nxtrm[2] <- nxtrm[2] + (watson.test(cunif)$statistic >= unif.test.0[2])
        nxtrm[3] <- nxtrm[3] + (rao.spacing.test(cunif)$statistic  >= unif.test.0[3])
        nxtrm[4] <- nxtrm[4] + (rayleigh.test(cunif)$statistic >= unif.test.0[4])
        setTxtProgressBar(pb, b)
    }
    pval <- nxtrm/(B+1)
    names(pval) <- c("kuiper", "watson", "rao", "rayleigh")
    close(pb)
    return(pval)
}

JP.psi.LR.test <- function(data, psi.0 = 0, alpha = 0.05) {
    
    null.model = "null"
    if (psi.0 == 0) {null.model <- "von Mises"}
    if (psi.0 == 1) {null.model <- "cardioid"}
    if (psi.0 ==-1) {null.model <- "wrapped Cauchy"}
    
    n <- length(data)
    s <- sum(sin(data))
    c <- sum(cos(data))
    mu.vM <- atan2(s,c) %% (2*pi)
    kappa.vM <- A1inv(sqrt(s*s+c*c)/n)
    
    JPnll.psi <- function(p){
        mu <- p[1]
        kappa <- p[2]
        psi <- p[3]
        parlim <- abs(kappa*psi)
        if (parlim > 10) {y <- 9999.0 ; return(y)}
        else {
            ncon <- JP.NCon(kappa, psi)
            y <- -sum(log(JP.pdf(data, mu, kappa, psi, ncon)))
            return (y)
        }
    }
    
    JPnll.psi.0 <- function(p){
        mu <- p[1]
        kappa <- p[2]
        psi <- psi.0 
        parlim <- abs(kappa*psi)
        if (parlim > 10) {y <- 9999.0 ; return(y)} 
        else {
            ncon <- JP.NCon(kappa, psi)
            y <- -sum(log(JP.pdf(data, mu, kappa, psi, ncon))) 
            return(y) 
        }
    }
    
    out <- optim(par=c(mu.vM, kappa.vM, 0), fn=JPnll.psi, gr = NULL, method = "L-BFGS-B", lower = c(mu.vM-pi, 0, -Inf), upper = c(mu.vM+pi, Inf, Inf))
    maxll1 <- -out$value
    muhat1 <- out$par[1]
    kaphat1 <- out$par[2]
    psihat1 <- out$par[3]
    
    out <- optim(par=c(muhat1, kaphat1), fn=JPnll.psi.0, gr = NULL, method = "L-BFGS-B", lower = c(muhat1-pi, 0), upper = c(muhat1+pi, Inf))
    maxll0 <- -out$value 
    muhat0 <- out$par[1] 
    kaphat0 <- out$par[2]
    
    D <- round(-2*(maxll0-maxll1),3)
    
    pval <- pchisq(D, df= 1, lower.tail=F)
    if (pval < alpha) {outcome = "gives"} else {outcome = "does not give"}
    pval <- round(pval, 3)
    
    comment = paste("Jones-Pewsey ", outcome, " an improvement on ", null.model,
                    " model at the ", alpha * 100, "% level.", sep = "")
    
    comparison <- round(rbind(max.ll = c(maxll0, maxll1),
                        mu = c(muhat0, muhat1),
                        kappa = c(kaphat0, kaphat1),
                        psi = c(psi.0, psihat1)),3)
    colnames(comparison) <- c(null.model, "Jones-Pewsey")
    
    list(D = D, p.val = pval, comment = comment, comparison = comparison)
}

JP.psi.info <- function(data, psi.0 = 0) {
    null.model = "null"
    if (psi.0 == 0) {null.model <- "von Mises"}
    if (psi.0 == 1) {null.model <- "cardioid"}
    if (psi.0 ==-1) {null.model <- "wrapped Cauchy"}
    
    x <- data
    n <- length(x)
    s <- sum(sin(x)) 
    c <- sum(cos(x))
    mu.vM <- atan2(s,c) %% (2 * pi)
    kappa.vM <- A1inv(sqrt(s*s+c*c)/n)
    
    JPnll <- function(p){
        mu <- p[1] 
        kappa <- p[2] 
        psi <- p[3] 
        parlim <- abs(kappa*psi)
        if (parlim > 10) {y <- 9999.0 ; return(y)}
        else {
            ncon <- JP.NCon(kappa, psi)
            y <- -sum(log(JP.pdf(x, mu, kappa, psi, ncon))) 
            return (y)
        }
    }
    
    JPnllpsi0 <- function(p){
        mu <- p[1] 
        kappa <- p[2] 
        psi <- psi.0 
        parlim <- abs(kappa*psi)
        if (parlim > 10) {y <- 9999.0 ; return(y)} 
        else {
            ncon <- JP.NCon(kappa, psi)
            y <- -sum(log(JP.pdf(x, mu, kappa, psi, ncon))) 
            return(y)
        }
    }
    
    out <- optim(par=c(mu.vM, kappa.vM, 0), fn=JPnll, gr = NULL, method = "L-BFGS-B", lower = c(mu.vM-pi, 0, -Inf), upper = c(mu.vM+pi, Inf, Inf))
    maxll1 <- -out$value 
    muhat1 <- out$par[1]
    kaphat1 <- out$par[2] 
    psihat1 <- out$par[3]
    nu <- 3
    AIC1 <- (2*nu)-(2*maxll1)
    BIC1 <- (log(n)*nu)-(2*maxll1) 
    
    out <- optim(par=c(muhat1, kaphat1), fn=JPnllpsi0, gr = NULL, method = "L-BFGS-B", lower = c(muhat1-pi, 0), upper = c(muhat1+pi, Inf))
    maxll0 <- -out$value 
    nu <- 2
    AIC0 <- (2*nu)-(2*maxll0)
    BIC0 <- (log(n)*nu)-(2*maxll0) 
    
    if (AIC0 < AIC1) {
        comment.AIC <- paste("AIC favours ", null.model, " model over full Jones-Pewsey distributon.", sep = "")
    } else {
        comment.AIC <- paste("AIC favours full Jones-Pewsey distribution over ", null.model, " model.", sep = "")
    }
    if (BIC0 < BIC1) {
        comment.BIC <- paste("BIC favours ", null.model, " model over full Jones-Pewsey distributon.", sep = "")
    } else {
        comment.BIC <- paste("BIC favours full Jones-Pewsey distribution over ", null.model, " model.", sep = "")
    }
    comparison <- round(rbind(mu = c(mu.vM, muhat1),
                              kappa = c(kappa.vM, kaphat1),
                              psi = c(psi.0, psihat1),
                              AIC = c(AIC0, AIC1),
                              BIC = c(BIC0, BIC1)),3)
    colnames(comparison) <- c(null.model, "Jones-Pewsey")
    
    list(comparison = comparison, AIC = comment.AIC, BIC = comment.BIC)
}

two.sample.QQ <- function(data1, data2) {
    
    n1 <- length(data1) 
    n2 <- length(data2) 
    nmin <- min(n1,n2) 
    nmax <- max(n1,n2)
    
    if (n2 < n1) {dataref <- data2 ; dataoth <- data1
    } else {dataref <- data1 ; dataoth <- data2}
    
    zref <- sin(0.5*(dataref - median.circular(dataref))) 
    szref <- sort(zref)
    
    zoth <- sin(0.5*(dataoth-median.circular(dataoth)))
    szoth <- sort(zoth)
    
    koth <- 0
    szothred <- 0
    szreffin <- 0
    
    for (k in 1:nmin) {
        koth[k] <- 1+nmax*(k-0.5)/nmin
        szothred[k] <- szoth[koth[k]] 
        szreffin[k] <- szref[k]
    }
    plot(szreffin, szothred, pch=16, xlim=c(-1,1), ylim=c(-1,1), cex.lab = 2, xlab = "Smaller sample", ylab = "Larger sample")
    xlim <- c(-1,1) ; ylim <- c(-1,1) 
    lines(xlim, ylim, lwd=2, col = "lightseagreen")
}

watson.common.mean.test <- function(samples) {
    
    data <- unlist(samples)
    N <- length(data)
    g <- length(samples)
    sample.sizes <- 0
    for (i in 1:g) {sample.sizes[i] <- length(samples[[i]])}
    
    size.csum <- cumsum(sample.sizes) 

    delhat <- 0 
    tbar <- 0

    for (k in 1:g) {
        sample <- samples[[k]]
    
        tm1 <- trigonometric.moment(sample, p=1)
        tm2 <- trigonometric.moment(sample, p=2)
    
        Rbar1 <- tm1$rho
        Rbar2 <- tm2$rho 
        tbar[k] <- tm1$mu %% (2*pi)
    
        delhat[k] <- (1-Rbar2)/(2*Rbar1*Rbar1)
    }

    dhatmax <- max(delhat) 
    dhatmin <- min(delhat)

    if (dhatmax/dhatmin <= 4) { # use P procedure
    
        CP <- 0
        SP <- 0
        dhat0 <- 0
    
        for (k in 1:g) {
            CP <- CP + sample.sizes[k]*cos(tbar[k])
            SP <- SP + sample.sizes[k]*sin(tbar[k])
            dhat0 <- dhat0 + sample.sizes[k]*delhat[k] 
        }
    
        dhat0 <- dhat0/N
        RP <- sqrt(CP*CP+SP*SP)
    
        Yg <- 2*(N-RP)/dhat0
    } else {
    
        CM <- 0 
        SM <- 0
        Yg <- 0
    
        for (k in 1:g) {
            CM <- CM + (sample.sizes[k]*cos(tbar[k])/delhat[k])
            SM <- SM + (sample.sizes[k]*sin(tbar[k])/delhat[k])
            Yg <- Yg + (sample.sizes[k]/delhat[k]) 
        }
        RM <- sqrt(CM*CM+SM*SM)
        Yg <- 2*(Yg-RM)
    }

    pval = pchisq(Yg, g-1, lower.tail = F)
    list(Y.g = Yg, p.val = pval, disp.ratio = dhatmax/dhatmin)
}

walraff.concentration.test <- function(samples) {
    
    data <- unlist(samples)
    g <- length(samples)
#    sample.sizes <- 0
    g.id <- c()
    for (i in 1:g) {
        g.id <- c(g.id, rep(i, length(samples[[i]])))
    }
    
    N <- length(data)
#    sample.sizescsum <- cumsum(sample.sizes) 

    tbar <- circular(0) 
    distdat <- c()
    for (k in 1:g) {
        
#        dist <- 0 
        sample <- samples[[k]]
    
        tm1 <- trigonometric.moment(sample, p=1) 
        tbar[k] <- tm1$mu %% (2*pi)
            
        dist <- pi-abs(pi-abs(sample-tbar[k]))
        distdat <- c(distdat, dist)
    }
    
    TestRes <- kruskal.test(distdat, g = g.id)
    
    list(p.val = TestRes$p.value, result = TestRes)
} 

cs.unif.scores <- function(samples) {
    
    data <- unlist(samples)
    N <- length(data)
    ranks <- rank(data, ties.method="random")
    cos.u.scores <- cos(ranks*2*pi/N)
    sin.u.scores <- sin(ranks*2*pi/N)
    
    list(cos.scores = cos.u.scores, sin.scores = sin.u.scores)    
}

mww.common.dist.ls <- function(cs.scores, sample.sizes) {
    
    N <- sum(sample.sizes)

    g <- length(sample.sizes)
    g.id <- c()
    for (i in 1:g) {
        g.id <- c(g.id, rep(i, sample.sizes[i]))
    }
        
    Wg <- 0
    
    for (k in 1:g) {
        cos.u.scores.k <- cs.scores$cos.scores[g.id == k] 
        sin.u.scores.k <- cs.scores$sin.scores[g.id == k] 
        
        sum.cos.k.sq <- (sum(cos.u.scores.k))^2
        sum.sin.k.sq <- (sum(sin.u.scores.k))^2
        
        Wg <- Wg+(sum.cos.k.sq+sum.sin.k.sq)/length(g.id[g.id == k])
    }
    Wg <- 2*Wg 
    p.val <- pchisq(Wg, 2*(g-1), lower.tail = F)
    
    list(W.g = Wg, p.val = p.val)    
}

mww.common.dist.rand <- function(samples, NR = 9999) {
    
    g <- length(samples)
    g.id <- c()
    sample.sizes <- c()
    for (i in 1:g) {
        sample.sizes[i] <- length(samples[[i]])
        g.id <- c(g.id, rep(i, length(samples[[i]])))
    }
    N <- sum(sample.sizes)
    
    cs.scores <- cs.unif.scores(samples)
    cos.u.scores <- cs.scores$cos.scores
    sin.u.scores <- cs.scores$sin.scores
    
    WgObs <- mww.common.dist.ls(cs.scores, sample.sizes)$W.g
    nxtrm <- 1
    
    pb <- txtProgressBar(min = 0, max = NR, style = 3)
    for (r in 1:NR) {
        cos.u.scores.rand <- c() 
        sin.u.scores.rand <- c()
        
        rand.ind <- sample(1:N, replace = F)
        
        for (k in 1:g) {            
            cos.u.scores.rand <- c(cos.u.scores.rand, cos.u.scores[rand.ind[g.id == k]])
            sin.u.scores.rand <- c(sin.u.scores.rand, sin.u.scores[rand.ind[g.id == k]])
        }
        
        cs.scores.rand <- list(cos.scores = cos.u.scores.rand, sin.scores = sin.u.scores.rand)
        
        WgRand <- mww.common.dist.ls(cs.scores.rand, sample.sizes)$W.g
        
        if (WgRand >= WgObs) { nxtrm <- nxtrm+1 }
        setTxtProgressBar(pb, r)
    }
    close(pb)
    nxtrm/(NR+1)
}
@

% ----------------------------------------------------------------------
% ----------------------------------------------------------------------
<<get-data, echo = F, out.width='0.45\\textwidth',size='small'>>=
m <- read.csv("~/Documents/ArchStats/Fitting-dists/Genlis-15-07-01-details.csv")
p <- m[m$type == 0, 4:5]

k.1 <- k.nearest.angles(p, 1)

q <- circular(k.1[,-c(1,2)][!is.na(k.1[,-c(1,2)])]) %% (2*pi)
q.2 <- (2*q) %% (2*pi)      # treat as linear axial data
q.4 <- (4*q) %% (2*pi)      # treat as perpendicular axial data

# get bias-corrected & ML point estimates
summ <- bc.point.estimates(q.4, sig = 0.05, symmetric = F)
vm.mle <-  mle.vonmises(q.4, bias = T)
vm.mle$mu <- vm.mle$mu %% (2*pi)
jp.mle <- jp.ci.nt(mle.jonespewsey(q.4), alpha = 0.05)
@

\section*{Genlis posthole midpoints, measured to nearest neighbour: \Sexpr{nrow(k.1)} angles}

<<get-bandwidths, echo = F, warning=F>>=
# NOT INCLUDED IN DOCUMENT - RUN THIS TO GET BW FOR KERNEL DENSITY ESTIMATION
bw.raw <- round(c(bw.cv.mse.circular(q), bw.cv.ml.circular(q), bw.nrd.circular(q)),0)
bw.1 <- round((bw.raw[1]+bw.raw[2])/2,0)

bw.mod.pi <- round(c(bw.cv.mse.circular(q.2), bw.cv.ml.circular(q.2), bw.nrd.circular(q.2)),0)
bw.2 <- round((bw.mod.pi[1]+bw.mod.pi[2])/2,0)

bw.mod.pi.2 <- round(c(bw.cv.mse.circular(q.4), bw.cv.ml.circular(q.4), bw.nrd.circular(q.4)),0)
bw.3 <- round((bw.mod.pi.2[1]+bw.mod.pi.2[2])/2,0)

bw.mod.pi.2 <- 50
@

Transformed data with kernel density estimate:
<<cplot-raw-data, echo = F, out.width = '0.32\\textwidth'>>=
plot(q, stack = T, sep = 0.05, pch = 20, shrink = 1.3, bins = 360)
title(expression("Raw data"), cex.main = 2)
lines(density.circular(q, bw = bw.1), col = "blue")

plot(q.2, stack = T, sep = 0.05, pch = 20, shrink = 1.3, bins = 180)
title(main = expression(paste("Modulo ", pi)), cex.main = 2)
lines(density.circular(q.2, bw = bw.2), col = "blue")

plot(q.4, stack = T, sep = 0.05, pch = 20, shrink = 1.3, bins = 90)
title(main = expression(paste("Modulo ", pi/2)), cex.main = 2)
lines(density.circular(q.4, bw = bw.mod.pi.2), col = "blue")
@

\vspace{-20pt}

<<uniformity-tests, echo = F, results='asis'>>=
kuip.unif.q <- "0.05 - 0.1"     # kuiper.test(q)
kuip.unif.q.2 <- "< 0.01"       # kuiper.test(q.2)
kuip.unif.q.4 <- "< 0.01"       # kuiper.test(q.4)

wats.unif.q <- "0.05 - 0.1"     # watson.test(q)
wats.unif.q.2 <- "< 0.01"       # watson.test(q.2)
wats.unif.q.4 <- "< 0.01"       # watson.test(q.4)

rao.unif.q <- "< 0.001"         # rao.spacing.test(q)
rao.unif.q.2 <- "< 0.001"       # rao.spacing.test(q.2)
rao.unif.q.4 <- "< 0.001"       # rao.spacing.test(q.4)

unif.tests <- rbind(cbind(kuip.unif.q, wats.unif.q, rao.unif.q, round(rayleigh.test(q)$p.value, 3), round(r.symm.test.stat(q)$p.val, 3), round(wilcox.test(q, mu = mean(q) %% (2*pi), correct = F)$p.value,3)),
                    cbind(kuip.unif.q.2, wats.unif.q.2, rao.unif.q.2, round(rayleigh.test(q.2)$p.value, 3), round(r.symm.test.stat(q.2)$p.val, 3), round(wilcox.test(q.2, mu = mean(q.2) %% (2*pi), correct = F)$p.value,3)),
                    cbind(kuip.unif.q.4, wats.unif.q.4, rao.unif.q.4, round(rayleigh.test(q.4)$p.value, 3), round(r.symm.test.stat(q.4)$p.val, 3), round(wilcox.test(q.4, mu = mean(q.4) %% (2*pi), correct = F)$p.value,3)))

rownames(unif.tests) <- c("Raw angles", "Modulo $\\pi$", "Modulo $\\pi/2$")
colnames(unif.tests) <- c("Kuiper", "Watson", "Rao", "Rayleigh", "Refl. symm", "Wilcoxon")

print(xtable(unif.tests, align = "r|ccc|c|rr",
             caption = "Tests of uniformity \\& reflective symmetry"), size = "footnotesize", 
      table.placement = "!h", caption.placement = "top", 
      sanitize.rownames.function = function(x){x},          # show special characters in row names
      sanitize.colnames.function = function(x) {paste('{\\textbf{',x,'}}', sep ='')})   # bold headers
@

\vspace{10pt}
Plots of data against candidate distributions with MLE parameters:
\vspace{-10pt}
<<plot-angles-and-densities, echo = F, out.width = '0.32\\textwidth', warning = FALSE>>=

# plot data with densities
plot(q.4, stack = T, sep = 0.05, pch = 20, shrink = 1.5, font = 3, ylim = c(-1.2,0.8), xlim = c(-1.1,0.9), bins = 90, col = "darkgrey")
lines(density.circular(q.4, bw = bw.mod.pi.2), lwd = 2)
arrows.circular(x = circular(summ$mu[1]), shrink = 1.7)

curve.circular(dvonmises(x, mu = vm.mle$mu, kappa = vm.mle$kappa), n = 3600, add = T, lty = 2, col = "blue", lwd = 2)
curve.circular(djonespewsey(x, mu = circular(jp.mle$mu[1]), kappa = jp.mle$kappa[1], psi = jp.mle$psi[1]), n = 3600, add = T, lty = 2, col = "red", lwd = 2)

# title(expression(paste("Angles modulo ", pi/2)), cex.main = 2)

legend("bottomright", bty = "n", cex = 1.5,
       legend = c("Kernel density estimate", "von Mises distribution", "Jones-Pewsey distribution"),
       col = c("Black", "Blue", "Red"),
       lty = c(1, 2, 2),
       lwd = 2)

# convert to linear plot - easier to see
q.4.l <- matrix(q.4)
kd <- cbind(density.circular(q.4, bw = bw.mod.pi.2)$x, density.circular(q.4, bw = bw.mod.pi.2)$y)

hist(q.4.l, breaks = 90, freq = F, ylim = c(0,1), col = "grey", border = "darkgrey", main = "", xlab = "", xaxt = "none")

axis(1, at = c(0, 0.5, 1, 1.5, 2) * pi,
     labels = c(0, expression(paste(pi, "/2")), expression(paste(pi)),
                expression(paste("3", pi, "/2")), expression(paste("2", pi))))

lines(kd, col = "black", lwd = 2)
curve(dvonmises(x, mu = vm.mle$mu, kappa = vm.mle$kappa), n = 3600, add = T, lty = 2, col = "blue", lwd = 2)
curve(djonespewsey(x, mu = circular(jp.mle$mu[1]), kappa = jp.mle$kappa[1], psi = jp.mle$psi[1]), n = 3600, add = T, lty = 2, col = "red", lwd = 2)

legend("topright", legend = c("Kernel density estimate", "von Mises candidate", "Jones-Pewsey candidate"),
       col = c("black", "Blue", "Red"), cex = 1,
       lwd = c(2,2,2), lty = c(1,2,2), bty = "n")

edf <- ecdf(q.4)
ncon <- JP.NCon(jp.mle$kappa[1], jp.mle$psi[1]) 
jp.tdf <- 0 
jp.tqf <- 0
for (j in 1:length(q.4)) {
    jp.tdf[j] <- JP.df(q.4[j], jp.mle$mu[1], jp.mle$kappa[1], jp.mle$psi[1], ncon)
    jp.tqf[j] <- JP.qf(edf(q.4[j]), jp.mle$mu[1], jp.mle$kappa[1], jp.mle$psi[1], ncon)}

plot.default(qvonmises(edf(q.4), vm.mle$mu, vm.mle$kappa, from=circular(0), tol = 1e-06),
     q.4, pch=20, xlim=c(0,2*pi), ylim=c(0,2*pi), asp = T, col = "darkgrey",
     xlab = "Distribution quantile function", ylab = "Empirical quantile function")
points(jp.tqf, q.4, pch=20)
lines(c(0,2*pi), c(0,2*pi), lwd=2, col = "red")
legend("bottomright", legend = c("von Mises", "Jones-Pewsey"), pch = 20, col = c("darkgrey", "black"))

@
\vspace{-10pt}

<<parameter-table, results='asis', echo = F>>=
e <- qnorm(0.975)

ests <- cbind(rbind(paste(round(summ$mu[1],3), " \\textsl{(", round(summ$mu[2],3), ", ", round(summ$mu[3],3), ")}", sep = ""),
              paste(round(summ$rho[1],3), " \\textsl{(", round(summ$rho[2],3), ", ", round(summ$rho[3],3), ")}", sep = ""),
              paste(round(A1inv(summ$rho[1]),3), " \\textsl{(", round(A1inv(summ$rho[2]),3), ", ", round(A1inv(summ$rho[3]),3), ")}", sep = ""),
              paste(round(summ$beta2[1],3), " \\textsl{(", round(summ$beta2[2],3), ", ", round(summ$beta2[3],3), ")}", sep = ""),
              paste(round(summ$alpha2[1],3), " \\textsl{(", round(summ$alpha2[2],3), ", ", round(summ$alpha2[3],3), ")}", sep = "")),
rbind(paste(round(vm.mle$mu,3), " \\textsl{(", round(vm.mle$mu - (e * vm.mle$se.mu),3), ", ", round(vm.mle$mu + (e * vm.mle$se.mu),3), ")}", sep = ""),
      paste(round(A1(vm.mle$kappa),3), " \\textsl{(", round(A1(vm.mle$kappa - (e * vm.mle$se.kappa)),3), ", ", round(A1(vm.mle$kappa + (e * vm.mle$se.kappa)),3), ")}", sep = ""),
      paste(round(vm.mle$kappa,3), " \\textsl{(", round(vm.mle$kappa - (e * vm.mle$se.kappa),3), ", ", round(vm.mle$kappa + (e * vm.mle$se.kappa),3), ")}", sep = ""),
      "-",  # no estimate of skewness, since assumed to be 0
      "-"), # no estimate of kurtosis, since assumed to be 0
rbind(paste(round(jp.mle$mu[1],3), " \\textsl{(", round(jp.mle$mu[2],3), ", ", round(jp.mle$mu[3],3), ")}", sep = ""),
      paste(round(A1(jp.mle$kappa[1]),3), " \\textsl{(", round(A1(jp.mle$kappa[2]),3), ", ", round(A1(jp.mle$kappa[3]),3), ")}", sep = ""),
      paste(round(jp.mle$kappa[1],3), " \\textsl{(", round(jp.mle$kappa[2],3), ", ", round(jp.mle$kappa[3],3), ")}", sep = ""),
      "-",  # no estimate of skewness, since assumed to be 0
      paste(round(jp.mle$psi[1],3), " \\textsl{(", round(jp.mle$psi[2],3), ", ", round(jp.mle$psi[3],3), ")}", sep = "")))

rownames(ests) <- c("Direction", "Res. length", "Concentration", "Skew", "Kurtosis / $\\psi$")
colnames(ests) <- c("Bias-corrected", "von Mises MLE", "Jones-Pewsey MLE")

print(xtable(ests, align = "r|c|c|c",
             caption = "Bias-corrected sample moments \\& parameter estimates:"),
      caption.placement = "top", size = "footnotesize", table.placement = "!h",
      sanitize.text.function = function(x){x},     # show special characters in cells
      sanitize.rownames.function = function(x){paste('{\\textbf{',x,'}}', sep ='')},  # bold
      sanitize.colnames.function = function(x) {paste('{\\textbf{',x,'}}', sep ='')})   # bold
@

<<OPTIONAL-BOOTSTRAP-TESTS, eval = F, echo = F>>=
# RUN THIS MANUALLY TO OBTAIN BOOTSTRAP VALUES IF USING
vm.boot <- vM.GoF.boot(q.4, B = 9999) # will take 10 minutes to run here.
jp.boot <- JP.GoF.boot(q.4, B = 999) # took about 90 minutes. Try with smaller B

# DO NOT SET EVAL = T: LAPTOP MAY EXPLODE
@

<<goodness-of-fit-tests, echo = F, results = 'asis'>>=
JP.info <- JP.psi.info(q.4, psi.0 = 0)
vm.unif <- circular(2*pi*pvonmises(q.4, vm.mle$mu, vm.mle$kappa, from=circular(0), tol = 1e-06))
jp.unif <- circular(2*pi*jp.tdf)

# MANUAL UPDATE NEEDED
    vm.boot.output <- c(1e-04, 1e-04, 1e-04, 1e-04)
    jp.boot.output <- c(0.1239, 0.2169, 0.0001, 0.3574)
include.bootstrap <- T

wats.vm.dist <- "< 0.01"        # watson.test(q.4, dist = "vonmises")

kuip.vm.unif <- "< 0.01"        # kuiper.test(vm.unif)
wats.vm.unif <- "< 0.01"        # watson.test(vm.unif)
rao.vm.unif <- "< 0.001"        # rao.spacing.test(vm.unif)

kuip.jp.unif <- "> 0.15"        # kuiper.test(jp.unif)
wats.jp.unif <- "> 0.10"        # watson.test(jp.unif)
rao.jp.unif <- "< 0.001"        # rao.spacing.test(jp.unif)

# AND WE'RE BACK TO AUTOMATION...

n.a <- "\\scriptsize{N/A}"

vm.fit <- cbind(wats.vm.dist, kuip.vm.unif, wats.vm.unif, rao.vm.unif,
                round(rayleigh.test(vm.unif)$p.val, 3), round(JP.info$comparison[4,1], 3), round(JP.info$comparison[5,1], 3))

jp.fit <- cbind(n.a, kuip.jp.unif, wats.jp.unif, rao.jp.unif,
                round(rayleigh.test(jp.unif)$p.val, 3), round(JP.info$comparison[4,2], 3), round(JP.info$comparison[5,2], 3))

vm.boot.fit <- c(n.a, round(vm.boot.output, 3), n.a, n.a)
jp.boot.fit <- c(n.a, round(jp.boot.output, 3), n.a, n.a)

if (include.bootstrap) {
    fitted <- rbind(vm.fit, vm.boot.fit, jp.fit, jp.boot.fit)
    rownames(fitted) <- c("von Mises", "vM bootstrap", "Jones-Pewsey", "J-P bootstrap")
} else {
    fitted <- rbind(vm.fit, jp.fit)
    rownames(fitted) <- c("von Mises", "Jones-Pewsey")
}
colnames(fitted) <- c("Watson vM", "Watson unif", "Kuiper unif", "Rao unif", "Rayleigh unif", "AIC", "BIC")

LR.test.pv <- JP.psi.LR.test(q.4, psi.0 = 0, alpha = 0.05)$p.val

if (LR.test.pv < 0.05) {
    LR.test.pref <- "Jones-Pewsey over von Mises"
} else {
    LR.test.pref <- "von Mises over Jones-Pewsey"
}

print(xtable(fitted, align = "r|c|cccc|cc",
             caption = "Comparison of Jones-Pewsey fit against von Mises with $\\psi = 0$:"),
      size = "footnotesize", caption.placement = "top", table.placement = "!h",
      sanitize.rownames.function = function(x){x},          # show special characters in row names
      sanitize.text.function = function(x){x},          # show special characters in row names
      sanitize.colnames.function = function(x) {paste('{\\textbf{',x,'}}', sep ='')},    # bold headers
      hline.after = c(-1, 0, nrow(fitted)))
@

\vspace{-10pt}

Likelihood ratio test favours \Sexpr{LR.test.pref}, with $p = $\Sexpr{LR.test.pv}.
\vspace{10pt}

The wrapped data is split into quadrants for comparison:
\vspace{-10pt}
<<split-and-plot-quadrants, echo = F, out.width='0.32\\textwidth'>>=
cutpoints <- circular(mean(q) + c(pi/4, 3*pi/4, 5*pi/4, 7*pi/4))
quadrant <- rep(0, length(q))
quadrant[q > cutpoints[1] & q < cutpoints[2]] <- 1
quadrant[q > cutpoints[3] & q < cutpoints[4]] <- 1

q.4.a <- q.4[quadrant == 0]
q.4.b <- q.4[quadrant == 1]

# get bias-corrected & ML point estimates
summ.a <- bc.point.estimates(q.4.a, sig = 0.05, symmetric = F)
vm.mle.a <-  mle.vonmises(q.4.a, bias = T)
vm.mle.a$mu <- vm.mle.a$mu %% (2*pi)
jp.mle.a <- jp.ci.nt(mle.jonespewsey(q.4.a), alpha = 0.05)

summ.b <- bc.point.estimates(q.4.b, sig = 0.05, symmetric = F)
vm.mle.b <-  mle.vonmises(q.4.b, bias = T)
vm.mle.b$mu <- vm.mle.b$mu %% (2*pi)
jp.mle.b <- jp.ci.nt(mle.jonespewsey(q.4.b), alpha = 0.05)

plot(q[quadrant == 0], stack = T, sep = 0.05, pch = 20, shrink = 1.5, font = 3, ylim = c(-1.2,0.8), xlim = c(-1.1,0.9), bins = 360, col = "black")
title(main = paste("All ", length(q), " angles"), cex.main = 2)
points(q[quadrant == 1], stack = T, sep = 0.05, pch = 20, bins = 360, col = "blue")

plot(q.4.a, stack = T, sep = 0.05, pch = 20, bins = 90, shrink = 1.5, ylim = c(-1.2,0.8), xlim = c(-1.5,0.5))
title(main = paste("Axis A: ", length(q.4.a), " angles"), cex.main = 2)
curve.circular(djonespewsey(x, mu = circular(jp.mle.a$mu[1]), kappa = jp.mle.a$kappa[1], psi = jp.mle.a$psi[1]), n = 3600, add = T, lty = 2, col = "lightseagreen", lwd = 2)
curve.circular(djonespewsey(x, mu = circular(jp.mle.b$mu[1]), kappa = jp.mle.b$kappa[1], psi = jp.mle.b$psi[1]), n = 3600, add = T, lty = 2, col = "mediumpurple2", lwd = 2)
curve.circular(djonespewsey(x, mu = circular(jp.mle$mu[1]), kappa = jp.mle$kappa[1], psi = jp.mle$psi[1]), n = 3600, add = T, lty = 1, col = "red", lwd = 2)
lines(density.circular(q.4.a, bw = bw.mod.pi.2), col = "grey")

legend("bottom", legend = c("Global Jones-Pewsey", "Quadrant A", "Quadrant B"), col = c("red", "lightseagreen", "mediumpurple2"), lty = c(1,2,2), lwd = 2, bty = "n")

plot(q.4.b, stack = T, sep = 0.05, pch = 20, bins = 90, shrink = 1.5, col = "blue", ylim = c(-1.2,0.8), xlim = c(-1.5,0.5))
curve.circular(djonespewsey(x, mu = circular(jp.mle.a$mu[1]), kappa = jp.mle.a$kappa[1], psi = jp.mle.a$psi[1]), n = 3600, add = T, lty = 2, col = "lightseagreen", lwd = 2)
curve.circular(djonespewsey(x, mu = circular(jp.mle.b$mu[1]), kappa = jp.mle.b$kappa[1], psi = jp.mle.b$psi[1]), n = 3600, add = T, lty = 2, col = "mediumpurple2", lwd = 2)
curve.circular(djonespewsey(x, mu = circular(jp.mle$mu[1]), kappa = jp.mle$kappa[1], psi = jp.mle$psi[1]), n = 3600, add = T, lty = 1, col = "red", lwd = 2)
lines(density.circular(q.4.b, bw = bw.mod.pi.2), col = "grey")

title(main = paste("Axis B: ", length(q.4.b), " angles"), cex.main = 2)
@

\vspace{-30pt}
<<quad-uniformity-tests, echo = F, results='asis'>>=
kuip.unif.a <- "< 0.01  "     # kuiper.test(q.4.a)
kuip.unif.b <- "< 0.01"       # kuiper.test(q.4.b)

wats.unif.a <- "< 0.01"       # watson.test(q.4.a)
wats.unif.b <- "< 0.01"       # watson.test(q.4.b)

rao.unif.a <- "< 0.001"       # rao.spacing.test(q.4.a)
rao.unif.b <- "< 0.001"       # rao.spacing.test(q.4.b)

quad.unif.tests <- rbind(cbind(kuip.unif.a, wats.unif.a, rao.unif.a, round(rayleigh.test(q.4.a)$p.value, 3), round(r.symm.test.stat(q.4.a)$p.val, 3), round(wilcox.test(q.4.a, mu = mean(q.4.a) %% (2*pi), correct = F)$p.value,3), round(wilcox.test(q.4.a, mu = jp.mle$mu[1], correct = F)$p.value,3)),
                    cbind(kuip.unif.b, wats.unif.b, rao.unif.b, round(rayleigh.test(q.4.b)$p.value, 3), round(r.symm.test.stat(q.4.b)$p.val, 3), round(wilcox.test(q.4.b, mu = mean(q.4.b) %% (2*pi), correct = F)$p.value,3), round(wilcox.test(q.4.b, mu = jp.mle$mu[1], correct = F)$p.value,3)))

rownames(quad.unif.tests) <- c("Quadrant A", "Quadrant B")
colnames(quad.unif.tests) <- c("Kuiper", "Watson", "Rao", "Rayleigh", "Refl. symm", "Wilcoxon (local)", "Wilcoxon (global)")

print(xtable(quad.unif.tests, align = "r|ccc|c|rrr",
             caption = "Tests of uniformity \\& reflective symmetry: about unspecified axis, about local axis ($\\bar{\\theta}_A, \\bar{\\theta}_B$), and about global axis ($\\hat{\\mu}_{JP}$)"),
      size = "footnotesize", caption.placement = "top",
      sanitize.rownames.function = function(x){x},          # show special characters in row names
      sanitize.colnames.function = function(x) {paste('{\\textbf{',x,'}}', sep ='')})   # bold headers
@

<<quad-parameter-table, results='asis', echo = F>>=
quad.ests <- cbind(
rbind(paste(round(summ.a$mu[1],2), " \\textsl{(", round(summ.a$mu[2],2), ", ", round(summ.a$mu[3],2), ")}", sep = ""),
      paste(round(summ.a$rho[1],2), " \\textsl{(", round(summ.a$rho[2],2), ", ", round(summ.a$rho[3],2), ")}", sep = ""),
      paste(round(A1inv(summ.a$rho[1]),2), " \\textsl{(", round(A1inv(summ.a$rho[2]),2), ", ", round(A1inv(summ.a$rho[3]),2), ")}", sep = ""),
      paste(round(summ.a$beta2[1],2), " \\textsl{(", round(summ.a$beta2[2],2), ", ", round(summ.a$beta2[3],2), ")}", sep = ""),
      paste(round(summ.a$alpha2[1],2), " \\textsl{(", round(summ.a$alpha2[2],2), ", ", round(summ.a$alpha2[3],2), ")}", sep = "")),

rbind(paste(round(summ.b$mu[1],2), " \\textsl{(", round(summ.b$mu[2],2), ", ", round(summ.b$mu[3],2), ")}", sep = ""),
      paste(round(summ.b$rho[1],2), " \\textsl{(", round(summ.b$rho[2],2), ", ", round(summ.b$rho[3],2), ")}", sep = ""),
      paste(round(A1inv(summ.b$rho[1]),2), " \\textsl{(", round(A1inv(summ.b$rho[2]),2), ", ", round(A1inv(summ.b$rho[3]),2), ")}", sep = ""),
      paste(round(summ.b$beta2[1],2), " \\textsl{(", round(summ.b$beta2[2],2), ", ", round(summ.b$beta2[3],2), ")}", sep = ""),
      paste(round(summ.b$alpha2[1],2), " \\textsl{(", round(summ.b$alpha2[2],2), ", ", round(summ.b$alpha2[3],2), ")}", sep = "")),

rbind(paste(round(vm.mle.a$mu,2), " \\textsl{(", round(vm.mle.a$mu - (e * vm.mle.a$se.mu),2), ", ", round(vm.mle.a$mu + (e * vm.mle.a$se.mu),2), ")}", sep = ""),
      paste(round(A1(vm.mle.a$kappa),2), " \\textsl{(", round(A1(vm.mle.a$kappa - (e * vm.mle.a$se.kappa)),2), ", ", round(A1(vm.mle.a$kappa + (e * vm.mle.a$se.kappa)),2), ")}", sep = ""),
      paste(round(vm.mle.a$kappa,2), " \\textsl{(", round(vm.mle.a$kappa - (e * vm.mle.a$se.kappa),2), ", ", round(vm.mle.a$kappa + (e * vm.mle.a$se.kappa),2), ")}", sep = ""),
      "-",  # no estimate of skewness, since assumed to be 0
      "-"),

rbind(paste(round(vm.mle.b$mu,2), " \\textsl{(", round(vm.mle.b$mu - (e * vm.mle.b$se.mu),2), ", ", round(vm.mle.b$mu + (e * vm.mle.b$se.mu),2), ")}", sep = ""),
      paste(round(A1(vm.mle.b$kappa),2), " \\textsl{(", round(A1(vm.mle.b$kappa - (e * vm.mle.b$se.kappa)),2), ", ", round(A1(vm.mle.b$kappa + (e * vm.mle.b$se.kappa)),2), ")}", sep = ""),
      paste(round(vm.mle.b$kappa,2), " \\textsl{(", round(vm.mle.b$kappa - (e * vm.mle.b$se.kappa),2), ", ", round(vm.mle.b$kappa + (e * vm.mle.b$se.kappa),2), ")}", sep = ""),
      "-",  # no estimate of skewness, since assumed to be 0
      "-"),

rbind(paste(round(jp.mle.a$mu[1],2), " \\textsl{(", round(jp.mle.a$mu[2],2), ", ", round(jp.mle.a$mu[3],2), ")}", sep = ""),
      paste(round(A1(jp.mle.a$kappa[1]),2), " \\textsl{(", round(A1(jp.mle.a$kappa[2]),2), ", ", round(A1(jp.mle.a$kappa[3]),2), ")}", sep = ""),
      paste(round(jp.mle.a$kappa[1],2), " \\textsl{(", round(jp.mle.a$kappa[2],2), ", ", round(jp.mle.a$kappa[3],2), ")}", sep = ""),
      "-",  # no estimate of skewness, since assumed to be 0
      paste(round(jp.mle.a$psi[1],2), " \\textsl{(", round(jp.mle.a$psi[2],2), ", ", round(jp.mle.a$psi[3],2), ")}", sep = "")),

rbind(paste(round(jp.mle.b$mu[1],2), " \\textsl{(", round(jp.mle.b$mu[2],2), ", ", round(jp.mle.b$mu[3],2), ")}", sep = ""),
      paste(round(A1(jp.mle.b$kappa[1]),2), " \\textsl{(", round(A1(jp.mle.b$kappa[2]),2), ", ", round(A1(jp.mle.b$kappa[3]),2), ")}", sep = ""),
      paste(round(jp.mle.b$kappa[1],2), " \\textsl{(", round(jp.mle.b$kappa[2],2), ", ", round(jp.mle.b$kappa[3],2), ")}", sep = ""),
      "-",  # no estimate of skewness, since assumed to be 0
      paste(round(jp.mle.b$psi[1],2), " \\textsl{(", round(jp.mle.b$psi[2],2), ", ", round(jp.mle.b$psi[3],2), ")}", sep = "")))
    
rownames(quad.ests) <- c("Direction", "Res. length", "Concentration",  "Skew", "Kurtosis / $\\psi$")
colnames(quad.ests) <- c("A", "B", " A", " B", "  A", "  B")

print(xtable(quad.ests, align = "r|cc|cc|cc",
             caption = "Bias-corrected sample moments \\& parameter estimates:",),
      size = "scriptsize", caption.placement="top",    
      add.to.row = list(pos = list(-1),
                        command = c(" & \\multicolumn{2}{c}{\\textbf{Bias-corrected}} & \\multicolumn{2}{c}{\\textbf{von Mises}} & \\multicolumn{2}{c}{\\textbf{Jones-Pewsey}} \\\\\n")),
      sanitize.text.function = function(x){x},     # show special characters in cells
      sanitize.rownames.function = function(x){paste('{\\textbf{',x,'}}', sep ='')},  # bold
      sanitize.colnames.function = function(x) {paste('{\\textbf{',x,'}}', sep ='')})   # bold
@

<<quad-goodness-of-fit, echo = F, results = 'asis'>>=
edf <- ecdf(q.4.a)
ncon.a <- JP.NCon(jp.mle.a$kappa[1], jp.mle.a$psi[1]) 
ncon.b <- JP.NCon(jp.mle.b$kappa[1], jp.mle.b$psi[1]) 
jp.tdf.a <- 0 
jp.tdf.b <- 0 
for (j in 1:length(q.4.a)) {
    jp.tdf.a[j] <- JP.df(q.4.a[j], jp.mle.a$mu[1], jp.mle.a$kappa[1], jp.mle.a$psi[1], ncon.a)
}
for (j in 1:length(q.4.b)) {
    jp.tdf.b[j] <- JP.df(q.4.b[j], jp.mle.b$mu[1], jp.mle.b$kappa[1], jp.mle.b$psi[1], ncon.b)
}

JP.info.a <- JP.psi.info(q.4.a, psi.0 = 0)
JP.info.b <- JP.psi.info(q.4.b, psi.0 = 0)

vm.unif.a <- circular(2*pi*pvonmises(q.4.a, vm.mle.a$mu, vm.mle.a$kappa, from=circular(0), tol = 1e-06))
jp.unif.a <- circular(2*pi*jp.tdf.a)

vm.unif.b <- circular(2*pi*pvonmises(q.4.b, vm.mle.b$mu, vm.mle.b$kappa, from=circular(0), tol = 1e-06))
jp.unif.b <- circular(2*pi*jp.tdf.b)

wats.vm.dist.a <- "< 0.01"        # watson.test(q.4.a, dist = "vonmises")

kuip.vm.unif.a <- "0.05 - 0.1"    # kuiper.test(vm.unif.a)
wats.vm.unif.a <- "0.05 - 0.1"    # watson.test(vm.unif.a)
rao.vm.unif.a <- "< 0.001"        # rao.spacing.test(vm.unif.a)

kuip.jp.unif.a <- "> 0.15"        # kuiper.test(jp.unif.a)
wats.jp.unif.a <- "> 0.10"        # watson.test(jp.unif.a)
rao.jp.unif.a <- "< 0.001"        # rao.spacing.test(jp.unif.a)

wats.vm.dist.b <- "< 0.01"        # watson.test(q.4.b, dist = "vonmises")

kuip.vm.unif.b <- "0.01 - 0.025"    # kuiper.test(vm.unif.b)
wats.vm.unif.b <- "0.025 - 0.05"    # watson.test(vm.unif.b)
rao.vm.unif.b <- "< 0.001"        # rao.spacing.test(vm.unif.b)

kuip.jp.unif.b <- "> 0.15"        # kuiper.test(jp.unif.b)
wats.jp.unif.b <- "> 0.10"        # watson.test(jp.unif.b)
rao.jp.unif.b <- "< 0.001"        # rao.spacing.test(jp.unif.b)

vm.fit.a <- cbind(wats.vm.dist.a, kuip.vm.unif.a, wats.vm.unif.a, rao.vm.unif.a,
                round(rayleigh.test(vm.unif.a)$p.val, 3), round(JP.info.a$comparison[4,1], 3), round(JP.info.a$comparison[5,1], 3))

jp.fit.a <- cbind(n.a, kuip.jp.unif.a, wats.jp.unif.a, rao.jp.unif.a,
                round(rayleigh.test(jp.unif.a)$p.val, 3), round(JP.info.a$comparison[4,2], 3), round(JP.info.a$comparison[5,2], 3))

vm.fit.b <- cbind(wats.vm.dist.b, kuip.vm.unif.b, wats.vm.unif.b, rao.vm.unif.b,
                round(rayleigh.test(vm.unif.b)$p.val, 3), round(JP.info.b$comparison[4,1], 3), round(JP.info.b$comparison[5,1], 3))

jp.fit.b <- cbind(n.a, kuip.jp.unif.b, wats.jp.unif.b, rao.jp.unif.b,
                round(rayleigh.test(jp.unif.b)$p.val, 3), round(JP.info.b$comparison[4,2], 3), round(JP.info.b$comparison[5,2], 3))

jp.tdf.test.a <- 0 
jp.tdf.test.b <- 0 
for (j in 1:length(q.4.a)) {
    jp.tdf.test.a[j] <- JP.df(q.4.a[j], jp.mle$mu[1], jp.mle$kappa[1], jp.mle$psi[1], ncon)
}
for (j in 1:length(q.4.b)) {
    jp.tdf.test.b[j] <- JP.df(q.4.b[j], jp.mle$mu[1], jp.mle$kappa[1], jp.mle$psi[1], ncon)
}

jp.unif.test.a <- circular(2*pi*jp.tdf.test.a)
jp.unif.test.b <- circular(2*pi*jp.tdf.test.b)

kuip.jp.unif.test.a <- "0.05 - 0.10"        # kuiper.test(jp.unif.test.a)
wats.jp.unif.test.a <- "> 0.10"        # watson.test(jp.unif.test.a)
rao.jp.unif.test.a <- "< 0.001"        # rao.spacing.test(jp.unif.test.a)

kuip.jp.unif.test.b <- "> 0.15"        # kuiper.test(jp.unif.test.b)
wats.jp.unif.test.b <- "> 0.10"        # watson.test(jp.unif.test.b)
rao.jp.unif.test.b <- "< 0.001"        # rao.spacing.test(jp.unif.test.b)

jp.test.fit.a <- cbind(n.a, kuip.jp.unif.test.a, wats.jp.unif.test.a, rao.jp.unif.test.a,
                  round(rayleigh.test(jp.unif.test.a)$p.val, 3), n.a, n.a)
jp.test.fit.b <- cbind(n.a, kuip.jp.unif.test.b, wats.jp.unif.test.b, rao.jp.unif.test.b,
                       round(rayleigh.test(jp.unif.test.b)$p.val, 3), n.a, n.a)
                       
fitted.a <- rbind(vm.fit.a, jp.fit.a, vm.fit.b, jp.fit.b, jp.test.fit.a, jp.test.fit.b)
rownames(fitted.a) <- c("von Mises (A)", "Jones-Pewsey (A)", "von Mises (B)",  "Jones-Pewsey (B)", "A vs global JP", "B vs global JP")

colnames(fitted.a) <- c("Watson vM", "Watson unif", "Kuiper unif", "Rao unif", "Rayleigh unif", "AIC", "BIC")

print(xtable(fitted.a, align = "r|c|cccc|cc",
             caption = "Goodness-of-fit tests for each quadrant against candidates with max. likelihood parameters"), 
      size = "footnotesize", caption.placement = "top", table.placement = "!h",
      sanitize.rownames.function = function(x){x},          # show special characters in row names
      sanitize.text.function = function(x){x},          # show special characters in row names
      sanitize.colnames.function = function(x) {paste('{\\textbf{',x,'}}', sep ='')},   # bold
      hline.after = c(-1, 0, 2, 4, 6))
@

<<quad-comparison-tests, echo = F, results = 'asis'>>=
q.sim <- circular(JP.sim(length(q), jp.mle$mu[1], jp.mle$kappa[1], jp.mle$psi[1], ncon))

mww.dist.rand <- 0.529       # round(mww.common.dist.rand(list(q.4.a, q.4.b), NR = 9999),3)
watson.dist.rand <- 0.342    # watson.two.test.rand(q.4.a, q.4.b, NR = 9999)$p.val

mww.dist.rand.a <- 0.539     # round(mww.common.dist.rand(list(q.4.a, q.sim), NR = 9999),3)
watson.dist.rand.a <- 0.432  # watson.two.test.rand(q.4.a, q.sim, NR = 9999)$p.val

mww.dist.rand.b <- 0.75     # round(mww.common.dist.rand(list(q.4.b, q.sim), NR = 9999),3)
watson.dist.rand.b <- 0.715  # watson.two.test.rand(q.4.b, q.sim, NR = 9999)$p.val

watson.dist <- "> 0.10"          # watson.two.test(q.4.a, q.4.b)
watson.dist.a <- "> 0.10"        # watson.two.test(q.4.a, q.sim)
watson.dist.b <- "> 0.10"        # watson.two.test(q.4.b, q.sim)

#------------------------------------------------------------------------------------------

quad.comp <- rbind(
    cbind(round(watson.common.mean.test(list(q.4.a, q.4.b))$p.val,3),
          round(walraff.concentration.test(list(q.4.a, q.4.b))$p.val,3),
          round(mww.common.dist.ls(cs.unif.scores(list(q.4.a, q.4.b)), c(length(q.4.a), length(q.4.b)))$p.val,3),
          mww.dist.rand, watson.dist, watson.dist.rand),
    cbind(round(watson.common.mean.test(list(q.4.a, q.sim))$p.val,3),
          round(walraff.concentration.test(list(q.4.a, q.sim))$p.val,3),
          round(mww.common.dist.ls(cs.unif.scores(list(q.4.a, q.sim)), c(length(q.4.a), length(q.sim)))$p.val,3),
          mww.dist.rand.a, watson.dist.a, watson.dist.rand.a),
    cbind(round(watson.common.mean.test(list(q.4.b, q.sim))$p.val,3),
          round(walraff.concentration.test(list(q.4.b, q.sim))$p.val,3),
          round(mww.common.dist.ls(cs.unif.scores(list(q.4.b, q.sim)), c(length(q.4.b), length(q.sim)))$p.val,3),
          mww.dist.rand.b, watson.dist.b, watson.dist.rand.b))

rownames(quad.comp) <- c("A vs B", "A vs global JP", "B vs global JP")
colnames(quad.comp) <- c("Watson (mean)", "Walraff (conc)", "MWW (dist)", "\\textsl{rand}", "Watson (dist)", " \\textsl{rand}")

print(xtable(quad.comp, align = "r|c|c|cc|cc",
             caption = "Distributional similarity of quadrants A and B, plus similarity to simulated Jones-Pewsey data with global MLE parameters:"), 
      size = "footnotesize", caption.placement = "top", table.placement = "!h",
      sanitize.text.function = function(x){x},         
      sanitize.colnames.function = function(x) {paste('{\\textbf{',x,'}}', sep ='')},  # bold
      hline.after = c(-1,0,1,3))  
@


\end{document}