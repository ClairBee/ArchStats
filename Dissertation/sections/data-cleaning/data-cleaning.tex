\documentclass[../../ArchStats.tex]{subfiles}

\graphicspath{{/home/clair/Documents/ArchStats/Dissertation/sections/data-cleaning/img/}}

\begin{document}
 
\section{Data cleaning}
\label{sec:data-cleaning}
Plans of dig sites of particular interest were provided by the PEML team in JPEG format; before any analysis can be carried out on the angular relationships between the post-holes and other features, the images must be converted into a set of points representing the locations of the features of interest.

There is no standard format for the printing and publication of archaeological plans - line weights, fonts, background colours and line types may all differ from one plan to another - so it is impossible to specify a precise set of steps that will work well for every image. In subsection \ref{sec:points-to-JPEG} we will describe a process that can be applied with reasonable results to any plan with certain characteristics, with more specific techniques described in section~\ref{sec:alternative-techniques}. In section \ref{sec:posts-to-angles}, the extraction of an appropriate set of angles to represent the orientation of the post-holes is discussed.



\subsection{Outline procedure to identify post-holes from a JPEG image}
\label{sec:points-to-JPEG}

We assume (hopefully not unreasonably) that all maps will be scanned in such a way that text and other annotations, such as the legend, are more or less horizontal. Image processing prior to loading the image into R should be kept to a minimum, but cropping out figure labels and borders that are clearly external to the site plan is a useful step. Where possible, the scale key and N-S axis arrow should be kept on the scanned image, so that all measurements taken from the data can be related to the site's true scale and orientation.

Our  focus is on the orientation of post-hole features; these are generally represented as solid points, and are smaller than the text used to annotate the plan. The procedure given is generally effective where this is the case; if the post-holes are represented as outlines or are larger than the text, or if linear features are to be extracted, then a different approach will be required. In all cases, a certain amount of trial and error is to be expected to establish the most appropriate procedure and parameters for a particular site plan, and some subjective judgement is necessary to assess when we have reached an `adequate' level of separation between post-hole and non-post-hole features.

One of the most important considerations when separating post-holes from other features must be to ensure that no regular annotations (such as text or site boundaries) are picked up and treated as part of the post-hole set. This would introduce lines of points along a shared orientation, which are likely to have more of an adverse effect on our analysis of the angles between the post-holes than would excluding a small number of post-holes or including one or two accidentally-introduced, but randomly distributed points.



\subsubsection{Extract features from a JPEG}
\label{sec:feat-ext}
The JPEG image is loaded and immediately converted to a raster object, which assigns a numerical value to  each pixel in the image. At this point, with no other information available from the JPEG file, the $x$-coordinates are set by default from 0 to 1 - with the resolution determined by the number of pixels in a row - and the $y$-coordinates are scaled in such a way that the aspect ratio of the image is maintained.

The raster values initially encode a full-colour image - although most of these colours will be shades of grey if the JPEG was of a black-and-white map - and the values must be binarized, replacing those below a certain threshold $t$ with 0 (a white pixel) and those above with 1 (a black pixel). For most black-and-white images, very similar results will generally be obtained with $0.1 < t < 0.9$; however, for full-colour images, a high value of $t$ might be necessary to avoid converting shaded areas to solid black, while for images with particularly fine or faint lines, a low value of $t$ will be more useful, to avoid  breaking those lines into small fragments that may resemble post-holes in size and shape. For most black-and-white images, a relatively low threshold of around $t = 0.2$ should be preferred; while small smudges and other `noise' features are more likely be picked up by such a low threshold, it is generally less potentially problematic to permit a few erroneous but randomly-distributed points such as these, rather than risk wrongly identifying groups of fragments of letters or site boundaries - which are more likely to appear in regular lines, and so to interfere with the angular analysis - as small, post-hole-type features.

Clumps of adjacent black pixels - including diagonally adjacent pixels, for the same reason that a lower $t$-value is recommended for lighter images - are identified and numbered sequentially for reference. These clumps represent features of the map, and may be post-holes, annotations, or lines denoting the edges of larger features; the raster object containing the feature numbers will henceforth be referred to as the feature raster. Individual features will now be selected for further analysis according to their shape, size, and proportions.


\subsubsection{Rescale the plan}
\label{sec:rescale}

As long as the map's annotations are horizontally aligned, the map's scale marker can be identified by designing a focal window that scores highly only when long, horizontal lines of black pixels are detected within it, and passing the window over the feature raster; the largest such horizontal feature is will generally be the scale marker. On user confirmation of the true distance represented by the feature thus identified, the feature raster's $x$ and $y$ coordinates can be rescaled, allowing analysis of the map to be carried out in approximately realistic units rather than the arbitrary resolution that would otherwise be used.

The accuracy of the revised scale will depend on both the scale and accuracy of the original map and the resolution of the JPEG image, so detailed conclusions about distances should be checked against more accurate measurements and revised accordingly. However, since our main interest is in finding well-separated regions of a site that share a similar orientation, the accuracy achieved should be sufficient.

Throughout this study, it will generally be assumed that all maps have been converted to their `true' scale in this way, unless stated otherwise. In practice, if rescaling of the map is not possible for some reason, all of the techniques listed may still be used, but estimation of distance-based parameters and assessments of the degree of separation between features must be made in arbitrary units.

Ideally, the direction of the N-S marker should also be measured, in order that the difference between true north and the measured directions can be taken into account when assessing the orientation of the site. However, the style and direction of the N-S marker varies massively between plans, making automatic identification very difficult. Manual identification of the group of pixels representing the N-S marker was used in the first case study, while the site map in the second had no scale marker.

\subsubsection{Exclude sparse features}
\label{sec:excl-sparse}

Positively identifying post-hole features directly is difficult without first performing a thorough investigation of the distributions of the dimensions of the features identified, which will vary from site to site and depend on such factors as the resolution of the image, the scale of the map, and stylistic choices made by the printers. It is generally more straightforward to begin with a set of all possible known features, and exclude those that we are confident are not post-holes. An initial step in this process that is generally extremely effective is to exclude any `sparse' features from the set of potential post-holes. For present purposes, a sparse feature is one for which, if we were to draw the smallest possible bounding square  around the feature, and to count the number of that square's pixels that are coloured black by the feature, the ratio of black to white pixels would be low.

Consider the relative proportions of pixellated shapes within our raster, with lengths and areas measured in pixel (or, interchangeably here, cell) units. An `ideal' post-hole feature would be a solid black circle of radius $r$,  covering an area of $\pi r^2$. A square bounding this shape would have sides of length $2r$, and cover an area of $4r^2$ , so the proportion of the square that is coloured black is $\nicefrac{\pi}{4}$ (around 0.79). At the opposite end of the scale, the sparsest feature that would require a square of this size to tightly bound it is a straight line of pixels, of length $2r$ and width 1, covering an area of $2r$; so the proportion of the cells that are coloured black by the line is $1/2r$, with the covered proportion decreasing as the length of the line increases. We will disregard as noise any cluster of only 1 or 2 cells, so the shortest possible line is 3 pixels long, giving a maximum possible ratio for strictly linear features of $\nicefrac{1}{3}$. A sensible starting threshold to divide sparse from dense features - and one which works well in practice - cuts midway between these two limits, at $\frac{\pi/4+1/3}{2}$, or about 0.55. 

Between these two extremes we should expect a great variety of possible shapes, each covering a different proportion of its bounding square; the exact threshold to be used may be adjusted to try to capture as much annotation as possible without incorrectly classifying too many post-holes. For sites with minimal annotation - such as the Catholme plan investigated in the second case study, which has no text other than the scale marker, and a boundary marked by a single solid line - this single function may be enough to filter out the small, dense post-hole features from the annotations and larger linear features.

\subsubsection{Exclude text and numbers}
\label{sec:closing}

Removing sparse features is unlikely to remove all annotations from the image, particularly if the text is only slightly larger than the post-hole features, or in a bold font; under these circumstances, the size and density of the characters may be very similar to that of the post-holes. However, text and numbers generally have more complex shapes than post-holes, and those that remain after the sparser feature characters (such as the letters l or L, or the number 1) are removed will generally contain closed or nearly-closed loops. We can identify any such features in our image using a morphological closing \cite{Serra1983}, consisting of two translations of the data: given a set of points $X \in \mathbb{R}^2$ and a structuring element $B$ \cite{Vincent1997},

\begin{description}
\item[Dilation] $\delta_B(X)$ of $X$ by $B$ is the set of points $x \in R^2$ such that the translation of $B$ by $x$ has a non-empty intersection with set $X$.
\vspace{-25pt}
\item[Erosion] $\varepsilon_B(X)$ of $X$ by $B$ is the set of points $x \in R^2$ such that the translation of $B$ by $x$ is included in $X$.
\vspace{-25pt}
\item[Closing] of $X$ by $B$ is given by $\phi_B(X) = \varepsilon_B(\delta_B(X))$.
\end{description}


The data is prepared by converting each of the remaining candidate features into a polygon by dissolving the boundaries between the black pixels and removing any enclosed white space, leaving only an outline of the feature. The set of points $X$ is the set of all points contained within the feature outline, and the structuring element a disc with a radius of 1 pixel-width: a larger choice of radius would result in more convex features after closing, but we are only interested in smoothing irregularities in the shapes, so a small radius is appropriate here. As shown in Figure~\ref{fig:morph-closing-example}, the dilation $\delta_B(X)$ contains all points that are covered by $B$ when the centre of $B$ is in $X$, while the erosion of $\delta_B(X)$ contains those that are covered by the centre of $B$ when all of $B$ is inside $\delta_B(X)$. Where the initial feature is convex and solid, the boundary is smoothed, but the number of cells covered is not changed, as in Figure~\ref{fig:closing-simple-1}; when the initial feature has concave edges, or a hole, the area covered by the closing will be larger than the area covered by the original feature. Any features whose closing covers more pixels than its original footprint, as in Figure~\ref{fig:closing-compl-1}, will therefore be excluded from the set of candidate post-holes.

\begin{figure}[h!]
\centering
\caption{Closing of features of differing complexity, showing changes to feature boundary after closing with $B$; the light blue hatched area is the new boundary at each step.\\ The footprint of the simpler convex post-hole is unchanged by the procedure, while the details of the complex annotation feature are smoothed by the closing, which covers 5 more complete pixels than the original shape.}
\label{fig:morph-closing-example}
%
\begin{subfigure}[b]{0.48\textwidth}
\caption{Simple (convex) post-hole feature}
\label{fig:closing-simple-1}
\centering
\includegraphics[scale=0.18]{cl-simple-1-org.pdf}
\includegraphics[scale=0.18]{cl-simple-2-dilated.pdf}
\includegraphics[scale=0.18]{cl-simple-3-eroded.pdf}
\end{subfigure}
%
\begin{subfigure}[b]{0.48\textwidth}
\caption{Complex (concave) annotation feature}
\label{fig:closing-compl-1}
\centering
\includegraphics[scale=0.18]{cl-complex-1-org.pdf}
\includegraphics[scale=0.18]{cl-complex-2-dilated.pdf}
\includegraphics[scale=0.18]{cl-complex-3-eroded.pdf}
\end{subfigure}
\end{figure}

Where post-holes are represented in the site plan as outlines rather than filled shapes, this closing should be used as a first step rather than filtering out sparse features, which is likely to filter out the hollow post-holes as well. However, morphological closing is computationally expensive and time-consuming, so where post-holes are solid features, a more efficient approach is to first filter out the sparse features, as suggested here.



\subsubsection{Fill in broken site boundaries}
\label{sec:site-boundaries}
The boundary of the excavation is generally marked with a solid, dashed or broken (dash-dot-dash \texttt{-$\cdot$-}) line. Even the shortest line segments will have been identified as sparse features, removing solid and dashed lines from the set of candidate features, but a broken line can be more problematic. In all but position, the dots are likely to resemble post-holes, but they lie on a straight line; if we accept them as post-holes and measure the angles between them, they will introduce an angular  bias into our data set. However, we can use that very characteristic to distinguish them from post-holes. For all of the sparsest features (say, all features for which less than 20\% of the bounding square is covered, to ensure that only line segments are included), we extend a line segment through the two most extreme points of the feature and outward for the feature's length, and identify any adjacent features that lie along this transect, or within an arc $1^\circ$ either side of it. Any feature that lies on two or more such transects is assumed to be part of a broken boundary line, and removed from the set of potential post-holes.


%=================================================================================

%\subsubsection{! Assess the shape of the remaining features}

%\nb{Is this even possible? Try boxplots of height, width, sparsity, w/h ratio, abs. size. Give examples.}

%\nb{Also consider: many are conservative (ie. likely to leave points as post-holes, rather than exclude them): won't remove post-holes without good reason. Particularly removal of sparse features, tall features (add function for wide features?), points between annotation marks: all of these should be fairly specific ways of removing only points that aren't post-holes.}

% ====================================================================================

\subsubsection{Additional filtering methods}
\label{sec:alternative-techniques}

While the procedure above is adequate for many sites, there are a number of other techniques that may be useful alongside or in place of those listed above. An approach that is best used when only a few annotations remain among the post-holes, and when the annotations are larger than the post-holes, is to remove any particularly tall features. Having obtained the heights of all of the features, we find the upper and lower quartiles, $q_{0.75}$ and $q_{0.25}$; then an `unusually tall' point is defined using a formula often applied to identify outliers in box plots, as one that lies above $q_{0.75} + 1.5(q_{0.75} - q_{0.25})$.

A less conservative approach, but one that requires a greater degree of parameter tuning, is to apply a simple filter to identify horizontal or vertical strips of black pixels, similar to that applied in \ref{sec:rescale} to identify the scale marker; the most effective filter size will need to be specified manually depending on the size of font used and the proportions of the site, although good results have been obtained over a number of sites using a vertical filter height of 9 (classifying any features with strips of 9 black pixels as an annotation), or a horizontal filter width of 7.

\subsection{Extract angles between post-holes}
\label{sec:posts-to-angles}

The mean $x$ and $y$ coordinates of the remaining post-holes can easily be obtained from the final feature raster, defining a set of points that represent all of the small, dense features identified in the site. However, not all of those features are necessarily of interest to us. We wish to investigate the orientation of the larger structures whose boundaries are marked by sets of post-holes, not of the post-holes themselves. Some further data cleaning is therefore required to remove those points that do not belong to a group representing any particular structure. 

\subsubsection{Removal of remote points}
\label{sec:filter-rectilinear}

A fairly conservative approach to distance-based post-hole removal is proposed, to ensure that only post-holes that are truly remote from their nearest neighbours are excluded from the data set. To avoid the need to  specify the value of a parameter determining an `acceptable' level of remoteness in terms of absolute distance from the nearest point, we again remove only  extreme values. Denoting the Euclidean distance from each point $i$ to its nearest neighbour as $\lambda_i$, $i$ is classed as an outlier if $\lambda_i > q_{0.75}(\boldsymbol{\lambda}) + 1.5 \left(q_{0.75}(\boldsymbol{\lambda}) - q_{0.75}(\boldsymbol{\lambda}) \right)$. Such remote points are unlikely to be related to any larger structures, so will generally be excluded from the angular analysis; of course, if expert advice gave reason to believe that remote points were in some way an important part of the overall structure of a site, we could omit this step.


\subsubsection{Measuring angles}

Buildings and other structures are generally slightly separated from one another, so post-holes that form part of a wall are generally likely to have as their nearest neighbours other post-holes which are part of the same wall - and so to share a common orientation (modulo $\nicefrac{\pi}{2}$) - while post-holes which do not lie within a structure may have as their nearest neighbour a point lying in any direction. In order to assess the post-holes' degree of alignment, an appropriate subset of the angles between them must be measured.

An initially appealing approach would be to obtain the angles between all points within a certain radius of one another. However, this method depends on the investigator to decide on an appropriate radius within which points are to be included. Where the true scale of the map is known, this may be feasible, although still  reliant on a subjective judgement of `appropriate' or `useful'. There is evidence \cite{Kendall2013} that walls and other structures may have been based on modules of between 4.5 and 5.5 metres (the exact measurement depending on the geographical location of the site under consideration), so treating points within around 5m of each other as part of the same structure, and measuring the angles between them, seems reasonable. However, for sites where the true scale is not known, estimation of an appropriate radius will be entirely subjective; it would be preferable to use a method that can be universally applied, with no estimating of parameters required. Furthermore, even if we were to find post-holes perfectly aligned along a perpendicular axial system, taking the set of angles between all points within a radius must include some angles between points that lie on different axes, diluting the distribution.

A more universal method is adopted here: a smaller, but more concentrated, set of angles is obtained by calculating the angle $\phi_i$ from each point $i$ to its single nearest neighbour, using the \textbf{atan2} function defined in (\ref{eqn:atan2}). The measured angles $\phi_i$ represent what we will refer to as the orientation of the points $i$ and is considered to be a fixed attribute of $i$; when subsets of points or angles are examined, the orientation will not be recalculated.



\subsubsection{Conversion of axial data into circular data}
Under our null assumption that the measured angles will tend to be concentrated around the perpendicular axes of an underlying grid, we expect the raw angles to be 4-cyclic, having 4 modes at right-angles to one another. The raw angles $\phi, \phi + \nicefrac{\pi}{2}, \phi + \pi,$ and $\phi + \nicefrac{3\pi}{2}$ reflect the same axis system, and so we wish to analyse them as the same angle $\theta = \phi \text{ (mod }\nicefrac{\pi}{2})$.
To this end we will follow Fisher's approach to $p$-axial data \cite{Fisher1993}, using $p=4$: the raw angles $\phi_i$ are transformed to $\theta_i = 4\phi_i \text{ (mod } 2\pi)$ or, equivalently, $\theta_i = 4 \times \left( \phi_i \text{ (mod }\nicefrac{\pi}{2})\right)$. Raw angles $\phi_i$ that share a perpendicular orientation - that is, angles that are directly opposed or perpendicular to one another - are thus mapped to the same angle $\theta_i$,  giving a unimodal data set with support $(0, 2\pi)$, to which we can fit a circular distribution, allowing us to make inferences on the shape of the distribution.


 
After a distribution has been fitted to the transformed angles $\mathbf{\theta}$, the mean sample direction obtained will be back-transformed by dividing by 4, to give the direction of one (and hence, trivially, all) of the axes of the grid. As per Fisher's recommendation, measures of dispersion such as the mean resultant length $\bar{R}$ will not be back-transformed, but will be given in terms of the transformed data.





\end{document}