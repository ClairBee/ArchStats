\documentclass[../../ArchStats.tex]{subfiles}


\begin{document}

\section{Evidence of gridding}
\label{sec:gridding}
We begin this section by describing a set of tests that can be used to fit and compare circular models to a single sample of angles, then move on to consider tests of similarity of multiple sample. Finally we proposed a method by which a site can be partitioned so that the distribution of the orientations within each region can be compared. Case studies applying the procedure to plans of dig sites of interest will be examined in sections \ref{sec:CS1} and \ref{sec:CS2}.

\subsection{Tests to fit and select models}
\label{sec:model-fitting-tests}

Before attempting to fit a model to the data, we must first decide whether it is appropriate to do so. The distributions that we expect to see if the post-holes are aligned to a perpendicular grid are all unimodal and reflectively symmetric, so a sensible first step is to test whether these assumptions are supported by the data. Having determined that they are, candidate models are fitted using maximum-likelihood estimation, as in Sections~\ref{sec:vM-params} and~\ref{sec:JP-params}; methods to assess the fit of these models are given in section \ref{sec:GoF}.


\subsubsection{Tests of non-uniformity}
\label{sec:unif-tests}

The most powerful test of the null hypothesis of uniformity against a specifically unimodal alternative with an unspecified mean direction is the Rayleigh test, which is the likelihood ratio test of uniformity against a von Mises alternative, and also the score test of uniformity within the von Mises model. Various approximations and refinements have been proposed ~\cite{Mardia1999}, but the test statistic is generally given as $2n\bar{R}^2 \, \dot{\sim} \, \chi^2_2$.

Since, under the assumption of an underlying grid, we expect the distribution to be unimodal, this will be our primary test. However, the test is less powerful against multi-modal alternatives, and is not consistent when $\rho = 0$ (particularly when the data has antipodal symmetry). Although we don't expect this to occur in the transformed angles, we should nonetheless consider alternative tests that are better able to deal with the eventuality should it arise.

Omnibus tests that are consistent against any alternative (although less powerful against a unimodal alternative) are Kuiper's test - which measures the maximum deviation between the empirical and circular uniform cumulative distribution functions - and Watson's $U^2$ test, which is based on the corrected mean square deviation. 

Given the empirical distribution function $S_n$ of the ordered observations $\theta_{(0)}, \theta_{(1)}, \dots, \theta_{(n)}, \theta_{(n+1)}$ (where $\theta_{(0)} = 0$ and $\theta_{(n+1)} = 2\pi$), with $S_n(\theta) = i/n$ if $\theta_{(i)} \leq \theta < \theta_{(i+1)}$, $i = 0,1,\dots, n$, and the cumulative distribution function $F(\theta) = \theta/2\pi$ of the circular uniform distribution, Kuiper's test statistic is defined as
\begin{equation}
V_n = \sup_\theta \left\lbrace S_n(\theta) - F(\theta) \right\rbrace + 
\sup_\theta \left\lbrace F(\theta) - S_n(\theta) \right\rbrace 
\end{equation}
and Watson's as
\begin{equation}
U^2 = n \int_0^{2\pi} \left\lbrace S_n(\theta) - \frac{\theta}{2\pi} - \left(\frac{1}{2} - \frac{1}{n} \sum_{i=1}^n \frac{\theta_{(i)}}{2\pi} \right) \right\rbrace^2 \frac{1}{2\pi}\, d\theta.
\end{equation}

Exact $p$-values are not available for these tests, so a range must be obtained from tables \cite{Mardia1999}. In theory and in practice, there is no pressing reason to favour one over the other here; both generally give a similar range of $p$-values when presented with the same data set. Since computation and interpretation are neither difficult nor costly, we will retain both tests.

A final test of uniformity recommended by \cite{Pewsey2014} is the Rao spacing test. This test uses the fact that, in a circular uniform distribution, the expected arc length $T_i = \theta_{(i)} - \theta_{(i-1)}$ between successive ordered angles, is 
$\mathbb{E}\left[T_i\right] = 2\pi/n$ , and rejects uniformity when $\sum_{i=1}^n \vert T_i - \frac{2\pi}{n}\vert$ is large. This test can be useful in detecting clustering, but when confronted with data that shows both concentration in one region of the circle and larger-than-expected gaps in another region, it tends to be more conservative than the other tests described, consistently producing a lower $p$-value. For this reason, the Rao spacing test will not be used here.


\subsubsection{Test of reflective symmetry}
\label{sec:refl-symmetry}

For sample sizes of 50 or more, Pewsey's test\cite{Pewsey2002} - based on the asymptotically normal distribution of the second central sine moment $\bar{b}_2$ (\ref{eqn:bar-b-2}), with test statistic $z = \bar{b}_2 / \sqrt{\widehat{\text{var}}(\bar{b}_2)}$, where $\widehat{\text{var}}(\bar{b}_2)$ is as defined in (\ref{eqn:var-b-2}) - may be applied. For samples of less than 50 observations, a bootstrap test is required: here, the data is symmetrized about the sample mean by appending $(2\bar{\theta} - \theta_1, \dots, 2\bar{\theta} - \theta_n)$ to the original $(\theta_1, \dots, \theta_n)$; the test statistic $z$ is calculated for $B$ bootstrap samples of size $2n$ drawn from the symmetric angle set; and the $p$ value is estimated by the proportion of the bootstrapped $z_B$ that are greater than or equal to that of the original sample.

\subsubsection{Tests of goodness of fit}
\label{sec:GoF}

Hypothesis tests of the goodness of fit of any circular distribution can be carried out using the circular analogue to the probability integral transform: given a set of angles $\mathbf{\theta} = (\theta_1, \dots, \theta_n)$ and a hypothesized continuous distribution function $\hat{F}(\theta)$, the transformed distribution function
\begin{equation}
U = 2\pi \, \hat{F}(\mathbf{\theta}) \text{ modulo } 2\pi
\end{equation}
will be uniform on the circle under the null hypothesis that the data is drawn from $\hat{f}(\theta)$. Any of the tests described in section ~\ref{sec:unif-tests} can be used to test the uniformity of the resulting distribution, but since we have no particular reason to expect the alternative to be unimodal, omnibus tests of uniformity against any general alternative, such as Kuiper's or Watson's $U^2$, should be preferred.

Since the parameters of $\hat{f}(\theta)$ have been estimated based on the data, the usual critical values of the tests do not apply. Although the difference is generally small for larger sample sizes, we will only use a parametric bootstrapped version of the test here,  both to ensure consistency between samples, and to account for the added uncertainty introduced by the parameter estimation. To test the goodness-of-fit of any circular distribution, the method is the same: maximum likelihood estimates of the parameters of the proposed distribution $\hat{f}(\theta)$ are calculated, and a test statistic  obtained for the chosen test of uniformity of $( 2\pi \hat{F}(\theta_1), \dots, 2\pi \hat{F}(\theta_n) )$. A set of $B$ parametric bootstrap samples are simulated from $\hat{f}(\theta; \hat{\mu}, \hat{\kappa}, (\hat{\psi}))$, and the procedure is repeated; the $p$ value is estimated by the proportion of bootstrapped test statistics that are greater than or equal to the test statistic from the observed data. If the data are plausibly modelled by the  proposed distribution, we expect circular uniformity of the transformed angles not to be rejected at our chosen significance level.

In addition to this formal test of absolute goodness of fit, probability plots will be used to assess whether a given model fits the data better in some regions than in others; and the mean squared error (MSE), $\frac{1}{n} \sum_{i=1}^n (\theta_i - \mathbb{E}\left[\theta_i\right])^2$, will be used to assess the fit of similar models. 

Where multiple models have been found to fit the data, the Akaike Information Criterion \cite{Akaike1974} will be used to assess which should be preferred as the most parsimonious of the candidates. Particularly when investigating subsets of angles, it is likely that relatively small samples will be encountered, and so we will use the corrected AIC, defined for a model with $k$ estimated parameters and a sample of size $n$ as
\begin{equation}
AIC_C = AIC + \frac{2k(k+1)}{n-k-1}
\end{equation}
where the raw AIC score is, as usual, $2k - 2\ell$, with $\ell$ the log-likelihood of the data. The candidate model with the lowest AIC$_C$ score is generally preferred, with any model $m$ for which AIC$_{C_m} - $AIC$_{C_{min}}$ is less than 2 are considered to be only slightly less suitable candidates than this optimum, and so we will choose whichever of these has the smallest number of parameters. Any models for which AIC$_{C_m} - $AIC$_{C_{min}}$ is greater than 10 are not supported by the AIC evidence.



\subsection{Testing for perpendicularity: comparing multiple samples}
\label{sec:similarity-tests}

Having fitted a unimodal model to the full data set, we now wish to demonstrate that the preferred direction in the transformed angles does not arise from only one axis in the raw angles; this would suggest that the post-holes lie predominantly along a series of parallel lines, rather than along both axes of a perpendicular grid. We test the null hypothesis of perpendicularity by dividing the transformed angles $\theta_i$ into subsets according to the direction of the raw angles $\phi_i$, and test whether the subsets might plausibly share an orientation, a concentration, or a distribution. It is prudent to include a test for uniformity of each of the quadrants in this set, since a uniform data set may be assigned any nominal mean orientation, but without displaying any particular trend in that direction.

The measured orientations $\boldsymbol{\phi}$ are discretized by rounding to 1 decimal place, and the modal angle $\phi_{max}$ of the discretized set identified. The data is then partitioned into four quadrants $Q_1, Q_2, Q_3, Q_4$, by cutting at $\phi_{max} + \frac{\pi}{4}, \phi_{max} + \frac{3\pi}{4}, \phi_{max} + \frac{5\pi}{4},$ and $\phi_{max} + \frac{7\pi}{4}$, so that $Q_1$ is centred on the modal direction; and the angles in opposing quadrants are pooled into 2 samples of samples, $Q_A = \{Q_1 \bigcup Q_3\}$ and $Q_B = (Q_2 \bigcup Q_4\}$, each representing one axis of the perpendicular grid. The tests that follow are then applied, although these can be applied to any number $r$ of samples $j = 1, \dots, r$ each having $n_i$ observations $\theta_{ji}, i = 1, \dots, n_j$, and a total of $N$ observations.


\subsubsection{Testing for a common mean}
\label{sec:common-mean-test}

An approach to testing the null hypothesis that two or more samples share a common mean direction, without any prior assumptions of common shape or dispersion, was proposed by Watson \cite{Watson1983}. The exact form of the test depends on the degree of circular dispersion $\hat{\delta}_j$ (\ref{eqn:delta-i}) in each sample; if all of the samples can be said to display a similar degree of dispersion (that is, if the ratio of the largest to the smallest within-sample dispersion $\hat{\delta}_{max} / \hat{\delta}_{min} \leq 4$), the test statistic is calculated from a pooled estimate
\begin{equation}
Y_r = 2(N - R_P) / \hat{\delta}_0,
\end{equation}
with
\begin{equation}
\begin{matrix*}
\hat{C}_P = \sum_{j=1}^r n_j \cos \bar{\theta}_j, &
\hat{S}_P = \sum_{j=1}^r n_j \sin \bar{\theta}_j, &
R_P = \sqrt{\hat{C}_P^2 + \hat{S}_P^2}, &
\hat{\delta}_0 = \sum_{j=1}^r n_j \hat{\delta}_ji / N.
\end{matrix*}
\end{equation}


If the dispersion weights are not comparable, the resultant length $R_M$ of the combined sample is weighted according to the sizes and dispersions of the individual samples, giving a test statistic
\begin{equation}
Y_r = 2\left(\sum_{j=1}^r \frac{n_j}{\hat{\delta}_j} - R_M\right)
\end{equation}
with 
\begin{equation}
\begin{matrix*}
\hat{C}_M = \sum_{j=1}^r n_j \cos \bar{\theta}_j / \hat{\delta}_j, &
\hat{S}_M = \sum_{j=1}^r n_j \sin \bar{\theta}_j / \hat{\delta}_j, &
R_M = \sqrt{\hat{C}_M^2 + \hat{S}_M^2}
\end{matrix*}
\end{equation}

Where all of the sample sizes are greater than 25, a large-sample version of the test is applicable, and the $p$-value can be obtained by comparing the observed value of  $Y_r$ to the quantiles of the $\chi^2_{r-1}$ distribution. 

If any of the samples contain less than 25 observations, a bootstrap version, as described in \cite[section 8.4.4]{Fisher1993}, will be used. The angles of each sample $j$ are centred around $\bar{\theta}_j$; each of $B$ bootstrap samples is obtained by resampling $n_j$ angles with replacement from each centred $j$, and the value $Y_r$ calculated for each bootstrap sample. The $p$-value is then estimated by the proportion of bootstrap samples for which the test statistic is greater than that of the observed data.



\subsubsection{Testing for common concentration}
\label{sec:common-concentration}

To test the null hypothesis of common concentration between samples (analogous to testing for homoscedasticity between samples of data on the real line) without assuming a particular underlying family of distributions, we will apply a nonparametric test credited to Wallraff \cite{Wallraff1979}. For each sample $j$, the distance between each observation $\theta_{ji}$ and the sample mean $\bar{\theta}_j$ is calculated as
	\begin{equation}
	d_{ji} = \pi - \left\vert \pi - \left\vert \theta_{ji} - 	\bar{\theta}_j \right\vert \right\vert,
	\end{equation}
and a Kruskal-Wallis rank sum test is applied to the distances.

\subsubsection{Testing for common distribution}

A nonparametric test of the null hypothesis that two or more samples share a common, unspecified distribution is the Mardia-Watson-Wheeler test \cite{Wheeler1962, Mardia1972}, a rank-based extension of the Rayleigh test of circular uniformity introduced in section \ref{sec:unif-tests}. The observations from the $r$ samples are combined into a single vector $\boldsymbol{\theta}$, the elements of which are ranked according to the (arbitrary) origin. For each sample $j$, the sums $S_j$ and $C_j$ of the sine and cosine uniform scores are defined as
	\begin{equation}
	\begin{matrix*}
	C_j = \sum_{i=1}^{n_j} \cos \left( \frac{2\pi \mathcal{R}_{ji}}{N} \right),  & \,  &
	S_j = \sum_{i=1}^{n_j} \sin \left( \frac{2\pi \mathcal{R}_{ji}}{N} \right),
	\end{matrix*} 
	\end{equation}
where $\mathcal{R}_{ji}$ here denotes the rank of the $i$th element of the $j$th sample. We can now calculate the test statistic
	\begin{equation}
	W_r = 2 \sum_{j=1}^r \frac{C_j^2 + S_j^2}{n_j}.
 	\end{equation}
Where all of the samples contain 10 or more observations, a large-sample version of the test is applicable, and $p$-values can be obtained by comparing the test statistic to the quantiles of the $\chi^2_{2(r-1)}$ distribution. Where any of the samples are small, a randomized version of the test should be used; $B$ the pairs of sine and cosine uniform scores $\left\lbrace \cos \left( \frac{2\pi \mathcal{R}_{ji}}{N}\right), \sin \left( \frac{2\pi \mathcal{R}_{ji}}{N}\right) \right\rbrace$ are assigned randomly among the $r$ groups to create each of $B$ randomized resamples, the test statistic is recalculated, and the $p$ value is estimated by the proportion of the $B$ randomized test statistics that are larger than the observed test statistic.

A test of common distribution should only be applied if the tests given in sections \ref{sec:common-mean-test} and \ref{sec:common-concentration} above have been applied, and have found no significant evidence against the assumption of a common parameter. The power of the Mardia-Watson-Wheeler test, as a general test of any difference in distribution between the samples, will be lower than the power of a test for a difference of a particular type; thus this test may not reject the null hypothesis of a shared distribution, even if the possibility of a common mean or concentration parameter has already been rejected. This result should not be viewed as contradictory, so much as a product of the lower power of the more general test. A more appropriate use of the Mardia-Watson-Wheeler test is as a final confirmation that there is no difference in the shape of the samples, after a common mean and concentration parameter have been established.


\subsection{Assessing the preponderance of the grid}

Quantifying the distribution of the regions of gridding, and establishing whether the observed distribution is significant, are problems that may have a solution in spatial statistics, but are beyond the scope of the present study; we will limit ourselves to describing the size and spread of the regions in which evidence of gridding can be observed, and therefore the degree to which any grid-orientation detected can be said to be universal. 

Having assigned each point $i$ to a cluster based on its angular distribution, we will also classify the points into a separate, parallel clustering based on their degree of spatial association. Comparison of the two clusterings will allow us to assess the degree to which a particular orientation is observable in particular regions of the site, and thus whether a preferred direction can be said to be global or local.

\subsubsection{Spatial clustering using DBscan}
\label{sec:DBscan}
Groups of points that are clumped together tightly - and thus, more likely to belong to the same building or other structural feature - can be identified using the DBscan algorithm \cite{Ester1996}. Any point with more than a specified number $MinPts$ of neighbours within a certain radius $\varepsilon$ will be considered to be part of a cluster, with points with common within-$\varepsilon$ neighbours allocated to the same cluster. The method is essentially deterministic for any particular pair of parameters $MinPts$ and $\varepsilon$ - points on the very border between two or more clusters may be allocated to one or the other on successive runs, depending on the algorithm's random starting point, but core points will always be grouped together - and, unlike other common clustering methods such as $k$-means or PAM, the algorithm is able to identify clusters of arbitrary shape. 

The algorithm is known to be very sensitive to the values of $MinPts$ and $\varepsilon$, and is designed to identify areas of high density, rather than the low-density areas bordered by points that are more generally characteristic of post-hole structures. However, we are not relying on the algorithm to accurately  identify individual buildings; our aim is simply to find groups of spatially-associated points, and for this purpose the algorithm performs adequately well as long as there is some separation between buildings. Following the recommendation of Ester et al \cite{Ester1996}, we will use $MinPts = 4$ and, where the data has been rescaled into metres, $\varepsilon = 5$. This choice approximately reflects the underlying module considered to be most likely to have been in use when the sites in question were laid out  \cite{Blair2013}. 

Where no natural choice of $\varepsilon$ is available, a graphical approach to selecting the value of the parameter may be employed. Still fixing $MinPts = 4$, the distances from each point to its 4 nearest neighbours are obtained, and plotted in ascending order. The distance at which an `elbow' appears in the plot can be used to estimate a value for $\varepsilon$ that is based on the characteristic density of the points. This approach will generally provide a range of plausible values for $\varepsilon$; we should generally prefer the largest plausible value of $\varepsilon$, since smaller values may tend to divide large features into sub-structures, tempting us to identify gridding across several clusters that should in fact be considered to be a single building.


\end{document}
