\documentclass[../../ArchStats.tex]{subfiles}

\begin{document}

\nb{We're looking for circular analogue to normal distribution: why? Need to justify this.}

% ADD IN UN-CITED TEXTS - STILL A REFERENCE


\section{Circular Distributions}

The main focus of the project will be the investigation of patterns in the angles between neighbouring post-holes; the data we will be working with will consist of sets of angles between pairs of points. The points are defined as pairs of coordinates, so the angles are calculated using the inverse tangent of the ratio of the difference in the $y$- and $x$-coordinates of two points. A common implementation is the \textbf{atan2} function, defined as

\begin{equation*}
\text{atan2} (y, x) = \left\lbrace \begin{matrix*}[l]
\arctan(y/x), & x > 0 \\
\arctan(y/x) + \pi, & x < 0, y \geq 0 \\
\arctan(y/x) - \pi, & x < 0, y < 0 \\
\pi/2, & x = 0, y > 0 \\
-\pi/2, & x = 0, y < 0 \\
\text{undefined}, & x = 0, y = 0 \\
\end{matrix*} \right. 
\end{equation*}

This function returns the arctan of the ratio of the $y$- and $x$- coordinates of a point from the origin, measured in radians from the positive horizontal axis, and unlike the simple inverse tangent function, returns an angle that reflects the quadrant in which the point lies. This choice of angular origin is essentially arbitrary - we could equally easily choose to measure directions against the y-axis, which would displace all of our measurements by $\pi/2$ - and is one of the reasons that directional  data such as these cannot be analysed by simply `flattening' them onto the real line and applying the same techniques that we would use for linear distributions. Such an analysis would not be able to reflect the fact that, in circular data, a measurement of $\theta = 1^\circ$ is closer, in terms of arc length, to $\theta = 359^\circ$ than to $\theta = 5^\circ$: the so-called `cross-over' problem \cite{Fisher1993}. Instead, we need to use methods specifically developed to handle circular data such as these; a brief introduction to which is the subject of this section. \nb{Mention need for methods that are invariant/equivariant under rotation of the data (that is, they are unaffected by choice of origin)?}



\subsection{Circular Descriptive Statistics}

The summary measures developed to describe linear measures are inappropriate for use with directional data, but circular analogues to the moments of a linear distribution can be easily obtained from the data. Since the angles have no magnitude, a useful formulation, known as the \textit{embedding approach}, is to consider the angle $\theta_j$ as the angle of a unit vector $\mathbf{x}_j$, where $\mathbf{x}_j = (\cos\theta_j, \sin\theta_j)$ are points on a unit circle. This approach allows us to perform certain operations on the angles with results that are invariant or equivariant under rotation - a key requirement in circular inference.


\subsubsection{Circular mean}

For unimodal, broadly symmetric data sets, the circular mean $\bar{\theta}$ is a useful measure of the central location of the data. Due to the `crossover' problem described earlier, we cannot use a simple arithmetic mean as we would for linear data; however, we can use the embedding approach already described to find a mean direction using vector addition. \nb{mention: arithmetic mean is not well defined.}

For a set of angles $\theta_1, \dots, \theta_n$ and corresponding unit vectors $\mathbf{x}_1, \dots, \mathbf{x}_n$, the direction of the resultant of $\mathbf{x}_1 + \dots + \mathbf{x}_n$ is the mean direction $\bar{\theta}$. Furthermore, this is the direction of the centre of mass $\mathbf{\bar{x}}$ of ($\mathbf{x}_1, \dots, \mathbf{x}_n$).

Since the Cartesian coordinates of each $\mathbf{x}_j$ are $(\cos\theta_j, \sin\theta_j)$, the Cartesian coordinates of $\mathbf{\bar{x}}$ are $(\bar{C}, \bar{S})$, where
	\begin{minipage}{0.5\linewidth}
	\[\bar{C} = \frac{1}{n} \sum_{j=1}^{n} \cos \theta_j,\]
	\end{minipage}
	\hspace{0.5cm}
	\begin{minipage}{0.5\linewidth}
	\[\bar{S} = \frac{1}{n} \sum_{j=1}^{n} \sin \theta_j.\]
	\end{minipage}
Given these coordinates, we can again use the inverse tangent function to find the direction of the mean resultant vector: 
\[\bar{\theta} = \text{atan2}(\bar{S}/\bar{C}).\]
 The sample mean thus obtained is equivariant under rotation, in the same way that the sample mean of a linear data set on the real line is equivariant under translation.


\subsubsection{Circular median}

A sample median direction can be described as any angle $\psi$ for which half of the observed points lie in an arc of length $\pi$ in a clockwise direction from $\psi$, and the other half of the points lie in an arc of length $\pi$ in an anticlockwise direction from $\psi$; while the majority of points are closer to $\psi$ than to $\psi \pm \pi$.  In circular data sets, there may be a number of such angles; a possible candidate is one that minimises the circular mean deviation,
\[d_2 = \frac{1}{n} \sum_{j=1}^n \left( \pi - \vert \pi - \vert \theta_j - \psi \vert \vert \right).\]
The median angle $\tilde{\theta}$ may be a more robust measure of location than the circular sample mean when the data are skewed; however, we generally do not expect to find heavily skewed data \nb{back this up! WHY?}, so will use the circular sample mean as our primary measure of the `preferred angle' of a distribution.


\subsubsection{Measures of dispersion and concentration}

The most commonly used measures of concentration and dispersion also arise from the embedded (vector) approach taken in calculating the sample mean direction. Having used the direction of the mean resultant vector $\mathbf{\bar{x}}$ to obtain $\bar{\theta}$, we have a measure of the concentration of the data in its length, 
\[\bar{R} = (\bar{C}^2 + \bar{S}^2)^{1/2}.\]
This measure is invariant under rotation and, since all of the vectors $\mathbf{x}_j$ are unit vectors, it must be the case that $0 \leq \bar{R} \leq 1$, which leads to a straightforward interpretation: if the values are clustered together tightly around the mean direction, then $\bar{R}$ will be close to 1; if they are widely dispersed, $\bar{R}$ will be close to 0. An analogue to the variance of a data set on the real line is the sample circular variance, $V = 1- \bar{R}$, which also takes values in $[0,1]$. 

It should be noted that if we were to observe $\bar{R} = 0$, we should not assume that this means that the directions are spread evenly around the circle; for example, a sample containing pairs of opposing angles $\theta_1, \dots, \theta_n$ and $\theta_1+\pi, \dots, \theta_n+\pi$ will have $\bar{R} = 0$, but the angles are not necessarily uniformly distributed about the circle. This effect will be observed in any data with a strongly cyclic structure.

Another useful measure of dispersion is the sample circular dispersion,
\[\hat{\delta} = \frac{1-\bar{R}_2}{2\bar{R}^2},\]
where $\bar{R}_2$ is the mean resultant length of the doubled angles $2\theta_1, \dots, 2\theta_n$. Although not usually used to describe data directly, this measure plays an important part in calculating confidence intervals for the mean direction of the data, and in comparing the means of multiple samples to determine whether they may plausibly arise from a similar underlying distribution. 

Other measures of the dispersion of the data are available, including an analogue to the  sample standard deviation, which can be useful when comparing angular data to a distribution on the real line: $\hat{\sigma} = \left\lbrace -2 \log \bar{R} \right\rbrace ^{1/2} \in [0, \infty]$. However, given that the circular distributions with which we will be working have finite support $[0, 2\pi)$, the finite-valued measures $\bar{R}$ and $V$ are generally a more natural choice here. In particular, because of its close relationship to the parameters of the candidate distributions, $\bar{R}$ will be used as the main measure of dispersion in this report.
 
%Mention Batschelet?

%\nb{is there a relationship between $\kappa$ and $n$ in eg. simulated data? (ie. can we adjust $\kappa$ according to $n$ and re-test for similarity of distribution?)}


\subsubsection{Shape: Skewness and Kurtosis}

\nb{do the functions make use of Mardia's standardized measures of skewness \& kurtosis? Or just the moments? Should really use the standardized values... but what is the difference?}

The second central sine moment, $\bar{b}_2$, is used as the basis of a measure of the skewness of the data about the mean direction:
\[ \bar{b}_2 = \frac{1}{n} \sum_{j=1}^n \sin 2(\theta_j-\bar{\theta}) = \bar{R}_2 \sin(\bar{\theta}_2 - 2\bar{\theta}) \]
where $\bar{R}_2$ is the mean resultant length of the doubled angles, and $\bar{\theta}_2$ is the mean direction of the doubled angles. This can itself be used directly as a measure of the skewness of the data, but more often used to describe the skewness of a sample is the standardized measure proposed by Mardia \cite{Mardia1972} on the basis of his work with concentrated circular distributions:
\[\hat{s} = \frac{\bar{b}_2}{(1-\bar{R})^{3/2}}\]
Values of $\hat{S}$ close to 0 indicate data that is near-symmetric about the mean, and larger  absolute values indicate data that is skewed away from the mean: in a clockwise direction for positive values, and anti-clockwise for negative. If $\bar{b}_2$ is used as the measure of skewness, we know that the maximum possible values are $\pm 1$, while the standardized measure can result in much larger absolute values; for example, data that is highly concentrated about the mean with $\bar{R} = 0.9$ will have $\hat{s} = \bar{b}_2 \times 31.6$, while data with low concentration and $\bar{R} = 0.1$ will have a standardized skewness of $\bar{b}_2 \times 1.2$.

Similarly, a basic measure of the sample kurtosis is given by the second central cosine moment, $\bar{a}_2$:
\[ \bar{a}_2 = \frac{1}{n} \sum_{j=1}^n cos 2(\theta_j-\bar{\theta}) = \bar{R}_2 cos(\bar{\theta}_2 - 2\bar{\theta}) \]
Values of $\bar{a}_2$ close to 1 indicate maximum peakedness of the distribution, with the data points almost identical; values close to 0 suggest that the data is near-evenly distributed around the circle. To compensate for the fact that kurtosis is so closely related to the mean resultant length, an adjustment is usually made, and $\bar{a}_2 - \bar{R}^4$ is usually given as the non-standardized measure of kurtosis, resulting in possible values between $-1$ and $1$ - although large negative values are unlikely, since this would require very low kurtosis and very high concentration. Values close to or below 0 indicate near-even distribution of the data, while larger values indicate a more peaked shape. A standardized measure of kurtosis, adjusted in a similar way to that already given for the skewness, is
\[ \hat{k} = \frac{\bar{a}_2 - \bar{R}^4}{(1-\bar{R})^2}\]
Again, values close to zero reflect low kurtosis, and data evenly spread around the circle. High negative values are unlikely to occur since, again, this would require the data to have very low kurtosis and very high concentration; high positive values of $\hat{k}$ will occur when the data has both high concentration and high kurtosis.

Importantly, unimodal symmetric distributions will tend to have zero skewness, and distributions such as von Mises and Wrapped Normal distributions will tend to have low or zero kurtosis, while more peaked distributions will tend to have higher kurtosis.

\nb{Dubious about this explanation. Maybe trim down \& avoid speculation. Or read Mardia's paper if time?}



\subsection{The `Circular Normal' or von Mises distribution}

%The circular analogue to the normal distribution is the wrapped normal distribution, in which a linear normal distribution with support $(-\infty, \infty)$ is wrapped onto a unit circle. However, although we might reasonably assume that a linear plot of the angles (modulo $2\pi$) will have a shape resembling that of a normal distribution, with values concentrated around the mean direction and lighter tails, our angles will have only a finite support, an arc of length $2\pi$ with arbitrary start and end points (generally, when plotting data, we will choose this arc to have range $\mu \pm \pi$): so the wrapped normal distribution is not as appropriate a choice as we might intially think. Furthermore, the circular distribution thus obtained is rather complicated, and unlike the standard normal distribution, does not belong to the exponential family; a more tractable choice, one so commonly used that it is often referred to as the circular normal distribution, is the von Mises distribution - which does belong to the exponential family, and can be used to closely approximate the wrapped normal distribution as well as others. \nb{is this relevant? Does it even need to be?}

\nb{Should definitely go into more detail on why vM is appropriate - we expect/hope for the data to be unimodal - ie. to have some non-zero degree of concentration, reflectively symmetric about the mean - ie. zero skew}

A von Mises distribution of an angle $\theta$ is usually written $\theta \sim M(\mu, \kappa)$, its two parameters being the circular mean $\mu$ and the concentration $\kappa$, and has probability density function
\[g(\theta; \mu, \kappa) = \frac{e^{\kappa \cos(\theta - mu)}}{2\pi I_0(\kappa)}\]
with $I_0(\kappa)$ the modified Bessel function of the first kind and order $p=0$, where
\[I_p(\kappa) = \frac{1}{2\pi}\int_0^{2\pi} \cos(p\theta)e^{\kappa \cos \theta} d\theta.\]
Although negative values of $\kappa$ are theoretically admissable, the convention is to take $\kappa > 0$, since $M(\mu, \kappa)$ and $M(\mu + \pi, \kappa)$ give the same distribution of $\theta$. This also lends itself to a simple, intuitive interpretation of the concentration parameter: when $\kappa = 0$, the distribution of $\theta$ is uniform about the circle, growing more concentrated about $\mu$ as $\kappa$ increases. 

The appeal of the von Mises distribution lies largely in its simplicity and tractability; however, for some datasets, this simplicity renders it inappropriate. Although it is able to describe the mean location and concentration of a set of angles, and - being symmetric - assumes that the data has zero skew. However, the degree of kurtosis in the data is not captured; in fact, for a von Mises distribution, it is expected to be close to 0\nb{cite}. In fact, the value of $\alpha_2$ does increase slightly with sample size $n$; tests using 100 identically distributed, independent samples of simulated von Mises samples of size 100 produced a mean $\alpha_2 = 0.01$, with a 95\% large-sample confidence interval of (-0.04, 0.24), suggesting that non-zero kurtosis is plausible; 100 samples of 1,000 gave mean $\alpha_2 =  0.11$, with CI (-0.04, 0.25); and 100 samples of 1,000,000 gave mean $\alpha_2 = 0.107$, with CI (0.105, 0.109). However, the data sets under consideration here are generally smaller than this - particularly when only a subset of the angles is examined - so generally, we can assume that a von Mises distribution should have $\alpha_2 \simeq 0$.
\nb{This needs to be more nuanced - depends on $\kappa$ as well. Kurtosis seems to level at around 0.4-0.5: what is the range of $\alpha_2$? If [0,1] then this statement may be irrelevant...}

Since we cannot guarantee that this is the case - and in fact, we might hope that it is not the case \nb{check simulations to see if this is so!} - we should also consider a more general distribution that is better able to handle data with non-zero kurtosis.
\nb{is kurtosis related to $\psi \kappa$ in any way?}


\subsection{A generalisation: the Jones-Pewsey distribution}


\subsection{Fitting and selecting a distribution}

\subsubsection{Testing for uniformity and reflective symmetry}

\subsubsection{Parameter estimation}

\subsubsection{Testing goodness of fit}

\subsubsection{Model comparison and selection}

For any unimodal angular data set obtained, there will be many potential candidate distributions, a number of which may be found to fit the data adequately. In order to select a single distribution from these plausible candidates, we will apply a parsimony estimator, selecting the candidate distribution for which the least information is lost. The most widely-used such estimators are the Akaike and Bayes Information Criterion (AIC and BIC, respectively).

It seems over-optimistic to hope to find the `true' distribution of the angles; the distribution generating the angles between nearest neighbours on a realistic site plan will be hugely complex, and would probably be most accurately represented by a mixture of a unimodal distribution (or distributions, if there are features with different alignments) and a circular uniform distribution, reflecting the `noise'  of post-holes not aligned to the orientations of other features. Our model will be a simplification of this scenario, and under these conditions - where we do not expect to find the `true' model, but only an approximation that would allow us to make the most accurate possible predictions - the Akaike Information Criterion (AIC) has been shown to perform better than the Bayes Information Criterion (BIC)\cite{aho2014}. If, however, we believed that the `true' generating distribution for our data was among the candidates, BIC would be a more appropriate choice, since it has been shown to outperform the AIC in such cases. \nb{or cite Burnham here?}

The AIC is based on the maximum log-likelihood of the data under the candidate model, with a correction for the number of parameters used\cite{Akaike1974}. For sample size $n$ and a model with $k$ parameters and likelihood $L$, 

\[AIC = 2k - 2 \ln (L)\]

Particularly when comparing subsets of angles, as described in \nb{link to section where gridding test is outlined}, we should consider the proviso raised by \cite{Burnham2004}: the AIC as proposed by Akaike  is not appropriate if $n/k \geq 40$. For a three-parameter Jones-Pewsey model, this means that the AIC will only be an appropriate measure of parsimony for samples of more than 120 angles. Since this is likely to frequently be the case, we will apply a second-order small sample correction, using

\[AIC_C = AIC + \frac{2k(k+1)}{n-k-1} \]

The absolute value of this score is heavily dependent on $n$, so it cannot be interpreted directly; given a set of scores AIC$_{C_i}$ for our candidate models, the model with the lowest score AIC$_{C_{min}}$ is selected as the most parsimonious. Any models for which AIC$_{C_i} - $AIC$_{C_{min}}$ is less than 2 are considered to be only slightly less suitable candidates, while any models for which AIC$_{C_i} - $AIC$_{C_{min}}$ is greater than 10 are not supported by the AIC evidence.

\nb{Not sure about keeping that last sentence in - see if I actually use that scale for anything}

\nb{What am I going to do with the final distribution? Test the fit of different regions against the whole? Wouldn't it be better to test against each other?}


\end{document}