\documentclass[../../ArchStats.tex]{subfiles}

\begin{document}

\nb{Mention finite support of circular data that makes linear analogues inappropriate}

\nb{We're looking for circular analogue to normal distribution: why?}




\section{Circular Distributions}

The main focus of the project will be the investigation of patterns in the angles between neighbouring post-holes; the data we will be working with will consist of sets of angles between pairs of points. The points are defined as pairs of coordinates, so the angles are calculated using the inverse tangent of the ratio of the difference in the $y$- and $x$-coordinates of two points. A common implementation is the \textbf{atan2} function, defined as

\begin{equation*}
\text{atan2} (y, x) = \left\lbrace \begin{matrix*}[l]
\arctan(y/x), & x > 0 \\
\arctan(y/x) + \pi, & x < 0, y \geq 0 \\
\arctan(y/x) - \pi, & x < 0, y < 0 \\
\pi/2, & x = 0, y > 0 \\
-\pi/2, & x = 0, y < 0 \\
\text{undefined}, & x = 0, y = 0 \\
\end{matrix*} \right. 
\end{equation*}

This function returns the arctan of the ratio of the $y$- and $x$- coordinates of a point from the origin, measured in radians from the positive horizontal axis. This choice of angular origin is essentially arbitrary - we could equally easily choose to measure directions against the y-axis, which would displace all of our measurements by $\pi/2$ - and is one of the reasons that directional  data such as these cannot be analysed by simply `flattening' them onto the real line and applying the same techniques that we would use for linear distributions. Such an analysis would not be able to reflect the fact that, in circular data, a measurement of $\theta = 1^\circ$ is closer, in terms of arc length, to $\theta = 359^\circ$ than to $\theta = 5^\circ$: the so-called `cross-over' problem \cite{Fisher1993}. Instead, we need to use methods specifically developed to handle circular data such as these; a brief introduction to which is the subject of this section. \nb{Mention need for methods that are invariant/equivariant under rotation of the data (that is, they are unaffected by choice of origin)?}





\subsection{Describing a circular distribution: Summary Statistics}

The summary measures developed to describe linear measures are inappropriate for use with directional data, but circular analogues to the moments of a linear distribution can be easily obtained from the data. Since the angles have no magnitude, a useful formulation, known as the \textit{embedding approach}, is to consider the angle $\theta_j$ as the angle of a unit vector $\mathbf{x}_j$, where $\mathbf{x}_j = (\cos\theta, \sin\theta)$ are points on a unit circle. This approach allows us to perform certain operations on the angles with results that are invariant or equivariant under rotation - a key requirement in circular inference.

\subsubsection{Circular mean}

For unimodal, broadly symmetric data sets, the circular mean $\bar{\theta}$ is a useful measure of the central location of the data. Due to the `crossover' problem, we cannot use a simple arithmetic mean as we would for linear data; however, we can use the embedding approach already described to find a mean direction using vector addition. \nb{mention: arithmetic mean is not well defined.}

For a set of angles $\theta_1, \dots, \theta_n$ and corresponding unit vectors $\mathbf{x}_1, \dots, \mathbf{x}_n$, the direction of the resultant of $\mathbf{x}_1 + \dots + \mathbf{x}_n$ is the mean direction $\bar{\theta}$. Furthermore, this is the direction of the centre of mass $\mathbf{\bar{x}}$ of ($\mathbf{x}_1, \dots, \mathbf{x}_n$).

Since the Cartesian coordinates of each $\mathbf{\bar{x}}_j$ are $(\cos\theta_j, \sin\theta_j)$, the Cartesian coordinates of the centre of mass $\mathbf{\bar{x}}$ are $(\bar{C}, \bar{S})$, where

	\begin{minipage}{0.5\linewidth}
	\[\bar{C} = \frac{1}{n} \sum_{j=1}^{n} \cos \theta_j,\]
	\end{minipage}
	\hspace{0.5cm}
	\begin{minipage}{0.5\linewidth}
	\[\bar{S} = \frac{1}{n} \sum_{j=1}^{n} \sin \theta_j.\]
	\end{minipage}
	
Given these coordinates, we can again use the inverse tangent function to find the direction of the mean resultant vector: $\bar{\theta} = \text{atan2}(\bar{S}/\bar{C})$. The sample mean thus obtained is equivariant under rotation, in the same way that the sample mean of a linear data set on the real line is equivariant under translation.


\subsubsection{Mean resultant length}
Since all of the vectors $\mathbf{x}_j$ are unit vectors, it must be the case that $0 \leq \bar{R} \leq 1$, and we can use this statistic as an approximate measure of the concentration of the angles observed; if the values are clustered together tightly, then $\bar{R}$ will be close to 1, while if they are widely dispersed, $\bar{R}$ will be close to 0. However, if we observe $\bar{R} = 0$, we cannot assume that the directions are spread evenly around the circle; a sample containing pairs of opposing angles $\theta_1, \dots, \theta_n$ and $\theta_1+\pi, \dots, \theta_n+\pi$ will have $\bar{R} = 0$, but the angles are not necessarily uniformly distributed about the circle. \nb{unlikely to arise in our data, though}

A related measure of the dispersion of the data is the sample circular variance, $V$, which also takes values in $[0,1]$, and is defined as $V = 1-\bar{R}$. Various other measures of dispersion have also been described, but since analysis of the dispersion of our data is not the primary focus here, and since $\bar{R}$ is closely related to the parameters of the distributions that we will be attempting to fit, we will content ourselves with only this one measure of dispersion.

\nb{is there a relationship between $\kappa$ and $n$ in eg. simulated data? (ie. can we adjust $\kappa$ according to $n$ and re-test for similarity of distribution?)}

\subsubsection{Skew}

\nb{Draw more of a parallel between circular \& linear distributions eg. in terms of central moments?}

\nb{do the functions make use of Mardia's standardized measures of skewness \& kurtosis? Or just the moments? Should really use the standardized values... but what is the difference?}

The second central sine moment is used as the basis of a measure of the skewness of the data about the mean direction:
\[ \bar{b}_2 = \frac{1}{n} \sum_{j=1}^n \sin 2(\theta_j-\bar{\theta}) = \bar{R}_2 \sin(\bar{\theta}_2 - 2\bar{\theta}) \]

where $\bar{R}_2$ is the mean resultant length of the doubled angles, and $\bar{\theta}_2$ is the mean direction of the doubled angles. This is itself sometimes used directly as a measure of the skewness of the data, although \nb{these aren't great with concentrated distributions? Check in Mardia}, so the following standardized measure will be used here \cite{Mardia1999}:

\[\hat{s} = \frac{\bar{b}_2}{(1-\bar{R})^{3/2}}\]

The interpretation of both $\bar{b}_2$ and $\hat{s}$ as a measure of skewness is similar: a data set that is symmetric about $\bar{theta}$ will have skewness close to 0, with larger absolute values reflecting a greater degree of skew. Positive skew represents skew in the clockwise direction, while negative skew suggests that the data is skewed in an anti-clockwise direction, away from the mean.

If we assume that our set of angles is drawn from a group of post-holes that lie more-or-less on a straight line (as per our underlying assumption of a grid), we would expect the distribution to be symmetric, with digressions from the target orientation equally likely to occur in either direction; so we would expect to see values of $\bar{b}_2$ and $\hat{s}$ close to 0.

\subsubsection{Kurtosis}
A basic measure of the sample kurtosis is often given by the second central cosine moment, $\bar{a}_2$:

\[ \bar{a}_2 = \frac{1}{n} \sum_{j=1}^n cos 2(\theta_j-\bar{\theta}) = \bar{R}_2 cos(\bar{\theta}_2 - 2\bar{\theta}) \]

Interpretation of this measure is, again, straightforward: if the data is evenly distributed around the circle, the kurtosis will be 0, with a maximum value of 1 occuring when the data points are all identical. As for the sample skewness, there is a standardized measure of kurtosis \cite{Mardia1999}, accounting for \nb{What is this accounting for?!}:

\[ \hat{k} = \frac{\bar{a}_2 - \bar{R}^4}{(1-\bar{R})^2}\]

Since $\bar{R} \in [0,1]$, the magnitude of $\hat{k}$ will be larger than that of $\bar{a}_2$



\subsection{The `Circular Normal' or von Mises distribution}

%The circular analogue to the normal distribution is the wrapped normal distribution, in which a linear normal distribution with support $(-\infty, \infty)$ is wrapped onto a unit circle. However, although we might reasonably assume that a linear plot of the angles (modulo $2\pi$) will have a shape resembling that of a normal distribution, with values concentrated around the mean direction and lighter tails, our angles will have only a finite support, an arc of length $2\pi$ with arbitrary start and end points (generally, when plotting data, we will choose this arc to have range $\mu \pm \pi$): so the wrapped normal distribution is not as appropriate a choice as we might intially think. Furthermore, the circular distribution thus obtained is rather complicated, and unlike the standard normal distribution, does not belong to the exponential family; a more tractable choice, one so commonly used that it is often referred to as the circular normal distribution, is the von Mises distribution - which does belong to the exponential family, and can be used to closely approximate the wrapped normal distribution as well as others. \nb{is this relevant? Does it even need to be?}

\nb{Should definitely go into more detail on why vM is appropriate - we expect/hope for the data to be unimodal - ie. to have some non-zero degree of concentration, reflectively symmetric about the mean - ie. zero skew}

A von Mises distribution of an angle $\theta$ is usually written $\theta \sim M(\mu, \kappa)$, its two parameters being the circular mean $\mu$ and the concentration $\kappa$, and has probability density function
\[g(\theta; \mu, \kappa) = \frac{e^{\kappa \cos(\theta - mu)}}{2\pi I_0(\kappa)}\]
with $I_0(\kappa)$ the modified Bessel function of the first kind and order $p=0$, where
\[I_p(\kappa) = \frac{1}{2\pi}\int_0^{2\pi} \cos(p\theta)e^{\kappa \cos \theta} d\theta.\]
Although negative values of $\kappa$ are theoretically admissable, the convention is to take $\kappa > 0$, since $M(\mu, \kappa)$ and $M(\mu + \pi, \kappa)$ give the same distribution of $\theta$. This also lends itself to a simple, intuitive interpretation of the concentration parameter: when $\kappa = 0$, the distribution of $\theta$ is uniform about the circle, growing more concentrated about $\mu$ as $\kappa$ increases. 

The appeal of the von Mises distribution lies largely in its simplicity and tractability; however, for some datasets, this simplicity renders it inappropriate. Although it is able to describe the mean location and concentration of a set of angles, and - being symmetric - assumes that the data has zero skew. However, the degree of kurtosis in the data is not captured; in fact, for a von Mises distribution, it is expected to be close to 0\nb{cite}. In fact, the value of $\alpha_2$ does increase slightly with sample size $n$; tests using 100 identically distributed, independent samples of simulated von Mises samples of size 100 produced a mean $\alpha_2 = 0.01$, with a 95\% large-sample confidence interval of (-0.04, 0.24), suggesting that non-zero kurtosis is plausible; 100 samples of 1,000 gave mean $\alpha_2 =  0.11$, with CI (-0.04, 0.25); and 100 samples of 1,000,000 gave mean $\alpha_2 = 0.107$, with CI (0.105, 0.109). However, the data sets under consideration here are generally smaller than this - particularly when only a subset of the angles is examined - so generally, we can assume that a von Mises distribution should have $\alpha_2 \simeq 0$.
\nb{This needs to be more nuanced - depends on $\kappa$ as well. Kurtosis seems to level at around 0.4-0.5: what is the range of $\alpha_2$? If [0,1] then this statement may be irrelevant...}

Since we cannot guarantee that this is the case - and in fact, we might hope that it is not the case \nb{check simulations to see if this is so!} - we should also consider a more general distribution that is better able to handle data with non-zero kurtosis.
\nb{is kurtosis related to $\psi \kappa$ in any way?}


\subsection{A generalisation: the Jones-Pewsey distribution}


\subsection{Fitting and selecting a distribution}

\subsubsection{Testing for uniformity and reflective symmetry}

\subsubsection{Parameter estimation}

\subsubsection{Testing goodness of fit}

\subsubsection{Model comparison and selection}

For any unimodal angular data set obtained, there will be many potential candidate distributions, a number of which may be found to fit the data adequately. In order to select a single distribution from these plausible candidates, we will apply a parsimony estimator, selecting the candidate distribution for which the least information is lost. The most widely-used such estimators are the Akaike and Bayes Information Criterion (AIC and BIC, respectively).

It seems over-optimistic to hope to find the `true' distribution of the angles; the distribution generating the angles between nearest neighbours on a realistic site plan will be hugely complex, and would probably be most accurately represented by a mixture of a unimodal distribution (or distributions, if there are features with different alignments) and a circular uniform distribution, reflecting the `noise'  of post-holes not aligned to the orientations of other features. Our model will be a simplification of this scenario, and under these conditions - where we do not expect to find the `true' model, but only an approximation that would allow us to make the most accurate possible predictions - the Akaike Information Criterion (AIC) has been shown to perform better than the Bayes Information Criterion (BIC)\cite{aho2014}. If, however, we believed that the `true' generating distribution for our data was among the candidates, BIC would be a more appropriate choice, since it has been shown to outperform the AIC in such cases. \nb{or cite Burnham here?}

The AIC is based on the maximum log-likelihood of the data under the candidate model, with a correction for the number of parameters used\cite{Akaike1974}. For sample size $n$ and a model with $k$ parameters and likelihood $L$, 

\[AIC = 2k - 2 \ln (L)\]

Particularly when comparing subsets of angles, as described in \nb{link to section where gridding test is outlined}, we should consider the proviso raised by \cite{Burnham2004}: the AIC as proposed by Akaike  is not appropriate if $n/k \geq 40$. For a three-parameter Jones-Pewsey model, this means that the AIC will only be an appropriate measure of parsimony for samples of more than 120 angles. Since this is likely to frequently be the case, we will apply a second-order small sample correction, using

\[AIC_C = AIC + \frac{2k(k+1)}{n-k-1} \]

The absolute value of this score is heavily dependent on $n$, so it cannot be interpreted directly; given a set of scores AIC$_{C_i}$ for our candidate models, the model with the lowest score AIC$_{C_{min}}$ is selected as the most parsimonious. Any models for which AIC$_{C_i} - $AIC$_{C_{min}}$ is less than 2 are considered to be only slightly less suitable candidates, while any models for which AIC$_{C_i} - $AIC$_{C_{min}}$ is greater than 10 are not supported by the AIC evidence.

\nb{Not sure about keeping that last sentence in - see if I actually use that scale for anything}

\nb{What am I going to do with the final distribution? Test the fit of different regions against the whole? Wouldn't it be better to test against each other?}


\end{document}